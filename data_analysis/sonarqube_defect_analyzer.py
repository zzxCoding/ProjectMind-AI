#!/usr/bin/env python3
"""
SonarQubeé¡¹ç›®ç¼ºé™·åˆ†æå™¨
åˆ†æSonarQubeé¡¹ç›®çš„ä»£ç è´¨é‡é—®é¢˜ï¼Œç”ŸæˆåŒ…å«AIåˆ†æçš„è¯¦ç»†æŠ¥å‘Š
"""

import os
import sys
import json
import argparse
from datetime import datetime
from typing import Dict, List, Any, Optional
from collections import defaultdict
import markdown

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)
from shared.utils import setup_logging, format_timestamp
from shared.sonarqube_client import SonarQubeClient, SonarQubeConfig
from shared.ollama_client import OllamaClient
from automation.notification_sender import NotificationSender

class SonarQubeDefectAnalyzer:
    """SonarQubeé¡¹ç›®ç¼ºé™·åˆ†æå™¨"""
    
    def __init__(self, project_key: str, sonarqube_client: Optional[SonarQubeClient] = None,
                 ollama_client: Optional[OllamaClient] = None, ai_model: Optional[str] = None):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            project_key: SonarQubeé¡¹ç›®æ ‡è¯†ç¬¦
            sonarqube_client: SonarQubeå®¢æˆ·ç«¯
            ollama_client: Ollama AIå®¢æˆ·ç«¯
            ai_model: æŒ‡å®šAIåˆ†æä½¿ç”¨çš„æ¨¡å‹åç§°
        """
        self.project_key = project_key
        self.sonarqube = sonarqube_client or SonarQubeClient()
        self.ollama = ollama_client or OllamaClient()
        self.ai_model = ai_model
        self.logger = setup_logging()
        self.notification_sender = NotificationSender()
    
    def analyze_project_defects(self, severities: List[str] = None,
                               issue_types: List[str] = None,
                               use_ai: bool = True) -> Dict[str, Any]:
        """
        åˆ†æé¡¹ç›®ç¼ºé™·
        
        Args:
            severities: ä¸¥é‡ç¨‹åº¦è¿‡æ»¤ ['INFO', 'MINOR', 'MAJOR', 'CRITICAL', 'BLOCKER']
            issue_types: é—®é¢˜ç±»å‹è¿‡æ»¤ ['CODE_SMELL', 'BUG', 'VULNERABILITY'] (Community Editionä¸æ”¯æŒSECURITY_HOTSPOT)
            use_ai: æ˜¯å¦ä½¿ç”¨AIåˆ†æ
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        self.logger.info(f"å¼€å§‹åˆ†æSonarQubeé¡¹ç›® {self.project_key} çš„ç¼ºé™·")
        
        # è®¾ç½®é»˜è®¤è¿‡æ»¤æ¡ä»¶
        if not severities:
            severities = ['CRITICAL', 'BLOCKER', 'MAJOR']
        if not issue_types:
            issue_types = ['BUG', 'VULNERABILITY', 'CODE_SMELL']  # Community Editionä¸æ”¯æŒSECURITY_HOTSPOT
        
        # è·å–é¡¹ç›®ä¿¡æ¯
        project_info = self.sonarqube.get_project_info(self.project_key)
        if not project_info:
            raise ValueError(f"æ— æ³•è·å–é¡¹ç›®ä¿¡æ¯: {self.project_key}")
        
        # è·å–é¡¹ç›®åº¦é‡æ•°æ®
        measures = self.sonarqube.get_project_measures(self.project_key)
        
        # è·å–è´¨é‡é—¨çŠ¶æ€
        quality_gate = self.sonarqube.get_quality_gate_status(self.project_key)
        
        # è·å–é—®é¢˜åˆ—è¡¨ï¼ˆä¿ç•™åŸå§‹æ•°æ®ç»Ÿè®¡ï¼‰
        self.logger.info("è·å–é¡¹ç›®é—®é¢˜æ•°æ®...")
        raw_issues = self.sonarqube.get_project_issues(
            self.project_key,
            severities=severities,
            types=issue_types,
            statuses=['OPEN', 'CONFIRMED', 'REOPENED']
        )
        
        # è®°å½•åŸå§‹é—®é¢˜æ•°é‡
        total_raw_issues = len(raw_issues)
        self.logger.info(f"åŸå§‹é—®é¢˜æ•°é‡: {total_raw_issues}")
        
        # å¦‚æœé—®é¢˜æ•°é‡è¿‡å¤šï¼Œè¿›è¡Œæ™ºèƒ½é‡‡æ ·
        if total_raw_issues > 2000:
            self.logger.warning(f"é—®é¢˜æ•°é‡è¿‡å¤š({total_raw_issues} > 2000)ï¼Œå¯ç”¨æ™ºèƒ½é‡‡æ ·")
            issues = self._manual_sampling(raw_issues, 2000)
        else:
            issues = raw_issues
        
        # è°ƒè¯•ï¼šæ£€æŸ¥è¿”å›çš„issuesç±»å‹
        self.logger.info(f"issuesç±»å‹: {type(issues)}")
        if issues and len(issues) > 0:
            self.logger.info(f"ç¬¬ä¸€ä¸ªissueç±»å‹: {type(issues[0])}")
            if isinstance(issues[0], dict):
                self.logger.info(f"ç¬¬ä¸€ä¸ªissueå†…å®¹: {list(issues[0].keys())}")
            else:
                self.logger.info(f"ç¬¬ä¸€ä¸ªissueå†…å®¹: {issues[0]}")
        
        # è·å–å®‰å…¨çƒ­ç‚¹
        hotspots = self.sonarqube.get_project_hotspots(
            self.project_key,
            statuses=['TO_REVIEW', 'ACKNOWLEDGED']
        )
        
        self.logger.info(f"è·å–åˆ° {len(issues)} ä¸ªé—®é¢˜ï¼Œ{len(hotspots)} ä¸ªå®‰å…¨çƒ­ç‚¹")
        
        # è°ƒè¯•ï¼šå†æ¬¡æ£€æŸ¥issueså†…å®¹
        self.logger.info(f"å‡†å¤‡åˆ†ç±»åˆ†æ - issuesç±»å‹: {type(issues)}")
        if issues:
            self.logger.info(f"issues[0]ç±»å‹: {type(issues[0]) if len(issues) > 0 else 'empty'}")
            if len(issues) > 0 and isinstance(issues[0], str):
                self.logger.error(f"æ£€æµ‹åˆ°å­—ç¬¦ä¸²ç±»å‹çš„issues: {issues[:5]}")  # æ˜¾ç¤ºå‰5ä¸ª
                # ä¿®å¤ï¼šå¦‚æœissuesæ˜¯å“åº”å¯¹è±¡çš„å­—æ®µååˆ—è¡¨ï¼Œå°è¯•ä»åŸå§‹å“åº”ä¸­æå–çœŸæ­£çš„é—®é¢˜
                self.logger.info("å°è¯•ä¿®å¤issuesæ•°æ®...")
                # é‡æ–°è·å–é—®é¢˜æ•°æ®
                fixed_issues = self.sonarqube.get_project_issues(
                    self.project_key,
                    severities=severities,
                    types=issue_types,
                    statuses=['OPEN', 'CONFIRMED', 'REOPENED']
                )
                self.logger.info(f"ä¿®å¤åçš„issuesç±»å‹: {type(fixed_issues)}")
                issues = fixed_issues
        
        # åˆ†ç±»åˆ†æé—®é¢˜
        categorized_issues = self._categorize_issues(issues)
        categorized_hotspots = self._categorize_hotspots(hotspots)
        
        # è®¡ç®—ç»Ÿè®¡æ‘˜è¦
        summary = self._calculate_summary(issues, raw_issues, total_raw_issues, hotspots, measures, quality_gate)
        
        # AIåˆ†æ
        ai_analysis = None
        if use_ai:
            self.logger.info("å¼€å§‹æ‰§è¡ŒAIç¼ºé™·åˆ†æ...")
            ai_analysis = self._generate_ai_analysis(
                issues, hotspots, measures, categorized_issues, categorized_hotspots
            )
            self.logger.info("AIç¼ºé™·åˆ†æå®Œæˆ")
        
        return {
            'project_info': project_info,
            'analysis_config': {
                'severities': severities,
                'issue_types': issue_types,
                'ai_analysis_enabled': use_ai
            },
            'summary': summary,
            'measures': measures,
            'quality_gate': quality_gate,
            'issues': {
                'raw_data': issues,
                'categorized': categorized_issues,
                'total_count': len(issues)
            },
            'security_hotspots': {
                'raw_data': hotspots,
                'categorized': categorized_hotspots,
                'total_count': len(hotspots)
            },
            'ai_analysis': ai_analysis,
            'ai_model_info': {
                'enabled': use_ai,
                'model': self.ai_model or self.ollama.config.default_model if use_ai else None
            },
            'generated_at': format_timestamp()
        }
    
    def _categorize_issues(self, issues: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
        """æŒ‰ç±»å‹å’Œä¸¥é‡æ€§åˆ†ç±»é—®é¢˜"""
        categorized = {
            'by_type': defaultdict(list),
            'by_severity': defaultdict(list),
            'by_component': defaultdict(list),
            'by_rule': defaultdict(list)
        }
        
        for issue in issues:
            # è°ƒè¯•ï¼šæ£€æŸ¥æ¯ä¸ªissueçš„ç±»å‹
            if not isinstance(issue, dict):
                self.logger.error(f"æœŸæœ›å­—å…¸ç±»å‹çš„issueï¼Œä½†å¾—åˆ°äº†: {type(issue)} - {issue}")
                continue
                
            issue_type = issue.get('type', 'UNKNOWN')
            severity = issue.get('severity', 'UNKNOWN')
            component = issue.get('component', 'UNKNOWN')
            rule = issue.get('rule', 'UNKNOWN')
            
            categorized['by_type'][issue_type].append(issue)
            categorized['by_severity'][severity].append(issue)
            categorized['by_component'][component].append(issue)
            categorized['by_rule'][rule].append(issue)
        
        # è½¬æ¢ä¸ºæ™®é€šå­—å…¸
        for category in categorized:
            categorized[category] = dict(categorized[category])
        
        return categorized
    
    def _categorize_hotspots(self, hotspots: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
        """æŒ‰ç±»åˆ«å’ŒçŠ¶æ€åˆ†ç±»å®‰å…¨çƒ­ç‚¹"""
        categorized = {
            'by_category': defaultdict(list),
            'by_status': defaultdict(list),
            'by_vulnerability_probability': defaultdict(list),
            'by_component': defaultdict(list)
        }
        
        for hotspot in hotspots:
            category = hotspot.get('securityCategory', 'UNKNOWN')
            status = hotspot.get('status', 'UNKNOWN')
            vuln_prob = hotspot.get('vulnerabilityProbability', 'UNKNOWN')
            component = hotspot.get('component', 'UNKNOWN')
            
            categorized['by_category'][category].append(hotspot)
            categorized['by_status'][status].append(hotspot)
            categorized['by_vulnerability_probability'][vuln_prob].append(hotspot)
            categorized['by_component'][component].append(hotspot)
        
        # è½¬æ¢ä¸ºæ™®é€šå­—å…¸
        for category in categorized:
            categorized[category] = dict(categorized[category])
        
        return categorized
    
    def _calculate_summary(self, issues: List[Dict[str, Any]], 
                          raw_issues: List[Dict[str, Any]],
                          total_raw_issues: int,
                          hotspots: List[Dict[str, Any]],
                          measures: Dict[str, Any],
                          quality_gate: Dict[str, Any]) -> Dict[str, Any]:
        """è®¡ç®—ç»Ÿè®¡æ‘˜è¦"""
        # é—®é¢˜ç»Ÿè®¡ï¼ˆåŸºäºåŸå§‹æ•°æ®ï¼‰
        issue_stats = {
            'total': total_raw_issues,  # åŸå§‹æ€»æ•°
            'by_type': {},
            'by_severity': {}
        }
        
        # åŸºäºåŸå§‹æ•°æ®è¿›è¡Œç»Ÿè®¡
        for issue in raw_issues:
            # ç±»å‹æ£€æŸ¥ï¼Œé˜²æ­¢å­—ç¬¦ä¸²é”™è¯¯
            if not isinstance(issue, dict):
                self.logger.error(f"æœŸæœ›å­—å…¸ç±»å‹çš„issueï¼Œä½†å¾—åˆ°äº†: {type(issue)} - {issue}")
                continue
                
            issue_type = issue.get('type', 'UNKNOWN')
            severity = issue.get('severity', 'UNKNOWN')
            
            issue_stats['by_type'][issue_type] = issue_stats['by_type'].get(issue_type, 0) + 1
            issue_stats['by_severity'][severity] = issue_stats['by_severity'].get(severity, 0) + 1
        
        # æ·»åŠ é‡‡æ ·ä¿¡æ¯
        issue_stats['sampled_total'] = len(issues)  # é‡‡æ ·åæ•°é‡
        issue_stats['sampled'] = total_raw_issues > 2000  # æ˜¯å¦ç»è¿‡é‡‡æ ·
        
        # å®‰å…¨çƒ­ç‚¹ç»Ÿè®¡
        hotspot_stats = {
            'total': len(hotspots),
            'by_category': {},
            'by_status': {},
            'by_vulnerability_probability': {}
        }
        
        for hotspot in hotspots:
            # ç±»å‹æ£€æŸ¥ï¼Œé˜²æ­¢å­—ç¬¦ä¸²é”™è¯¯
            if not isinstance(hotspot, dict):
                self.logger.error(f"æœŸæœ›å­—å…¸ç±»å‹çš„hotspotï¼Œä½†å¾—åˆ°äº†: {type(hotspot)} - {hotspot}")
                continue
                
            category = hotspot.get('securityCategory', 'UNKNOWN')
            status = hotspot.get('status', 'UNKNOWN')
            vuln_prob = hotspot.get('vulnerabilityProbability', 'UNKNOWN')
            
            hotspot_stats['by_category'][category] = hotspot_stats['by_category'].get(category, 0) + 1
            hotspot_stats['by_status'][status] = hotspot_stats['by_status'].get(status, 0) + 1
            hotspot_stats['by_vulnerability_probability'][vuln_prob] = hotspot_stats['by_vulnerability_probability'].get(vuln_prob, 0) + 1
        
        # è®¡ç®—é£é™©ç­‰çº§
        risk_level = self._calculate_risk_level(issue_stats, hotspot_stats, measures)
        
        # è´¨é‡é—¨çŠ¶æ€
        gate_status = quality_gate.get('status', 'UNKNOWN')
        gate_conditions = quality_gate.get('conditions', [])
        
        return {
            'issue_stats': issue_stats,
            'hotspot_stats': hotspot_stats,
            'quality_gate_status': gate_status,
            'quality_gate_conditions': len(gate_conditions),
            'failed_conditions': len([c for c in gate_conditions if c.get('status') == 'ERROR']),
            'risk_level': risk_level,
            'key_metrics': {
                'bugs': measures.get('bugs', 0),
                'vulnerabilities': measures.get('vulnerabilities', 0),
                'code_smells': measures.get('code_smells', 0),
                'security_hotspots': measures.get('security_hotspots', 0),
                'coverage': measures.get('coverage', 0),
                'duplicated_lines_density': measures.get('duplicated_lines_density', 0),
                'maintainability_rating': measures.get('maintainability_rating', 'A'),
                'reliability_rating': measures.get('reliability_rating', 'A'),
                'security_rating': measures.get('security_rating', 'A')
            }
        }
    
    def _calculate_risk_level(self, issue_stats: Dict[str, Any], 
                            hotspot_stats: Dict[str, Any],
                            measures: Dict[str, Any]) -> str:
        """è®¡ç®—é¡¹ç›®é£é™©ç­‰çº§"""
        score = 0
        
        # åŸºäºé—®é¢˜ä¸¥é‡æ€§è®¡ç®—åˆ†æ•°
        severity_weights = {'BLOCKER': 10, 'CRITICAL': 8, 'MAJOR': 5, 'MINOR': 2, 'INFO': 1}
        for severity, count in issue_stats.get('by_severity', {}).items():
            weight = severity_weights.get(severity, 1)
            score += count * weight
        
        # åŸºäºå®‰å…¨çƒ­ç‚¹è®¡ç®—åˆ†æ•°
        vuln_weights = {'HIGH': 8, 'MEDIUM': 5, 'LOW': 2}
        for prob, count in hotspot_stats.get('by_vulnerability_probability', {}).items():
            weight = vuln_weights.get(prob, 1)
            score += count * weight
        
        # åŸºäºåº¦é‡æ•°æ®è°ƒæ•´åˆ†æ•°
        bugs = measures.get('bugs', 0)
        vulnerabilities = measures.get('vulnerabilities', 0)
        score += bugs * 5 + vulnerabilities * 8
        
        # ç¡®å®šé£é™©ç­‰çº§
        if score >= 100:
            return 'CRITICAL'  # æé«˜é£é™©
        elif score >= 50:
            return 'HIGH'      # é«˜é£é™©
        elif score >= 20:
            return 'MEDIUM'    # ä¸­ç­‰é£é™©
        elif score >= 5:
            return 'LOW'       # ä½é£é™©
        else:
            return 'MINIMAL'   # æä½é£é™©
    
    def _generate_ai_analysis(self, issues: List[Dict[str, Any]], 
                            hotspots: List[Dict[str, Any]],
                            measures: Dict[str, Any],
                            categorized_issues: Dict[str, Any],
                            categorized_hotspots: Dict[str, Any]) -> str:
        """ç”ŸæˆAIåˆ†ææŠ¥å‘Š"""
        try:
            # æ„å»ºAIåˆ†ææç¤ºè¯
            # ğŸ†• å¢å¼ºç‰ˆAIåˆ†ææç¤ºè¯
            # è®¡ç®—é—®é¢˜æ¨¡å¼
            issue_patterns = self._analyze_issue_patterns_for_ai(issues)
            quality_score = self._calculate_quality_score_for_ai(measures, categorized_issues['by_severity'])
            
            prompt = f"""
ä½œä¸ºèµ„æ·±ä»£ç è´¨é‡ä¸“å®¶å’Œæ¶æ„å¸ˆï¼Œè¯·å¯¹ä»¥ä¸‹SonarQubeé¡¹ç›®è¿›è¡Œæ·±åº¦è´¨é‡åˆ†æï¼š

## é¡¹ç›®æ¦‚è§ˆ
- **é¡¹ç›®æ ‡è¯†**: {self.project_key}
- **åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ç»¼åˆè´¨é‡è¯„åˆ†**: {quality_score}/100

## è´¨é‡ç°çŠ¶åˆ†æ
**æ€»é—®é¢˜æ•°**: {len(issues)} | **å®‰å…¨çƒ­ç‚¹**: {len(hotspots)}

**é—®é¢˜åˆ†ç±»**:
"""
            
            # æ·»åŠ é—®é¢˜ç±»å‹ç»Ÿè®¡
            for issue_type, issues_list in categorized_issues['by_type'].items():
                prompt += f"- {issue_type}: {len(issues_list)}ä¸ª\n"
            
            prompt += "\n**ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ**:\n"
            for severity, issues_list in categorized_issues['by_severity'].items():
                prompt += f"- {severity}: {len(issues_list)}ä¸ª\n"
            
            prompt += f"\n## å…³é”®è´¨é‡æŒ‡æ ‡\n"
            prompt += f"- **å¯é æ€§**: Bugs({measures.get('bugs', 0)}) | è¯„çº§({measures.get('reliability_rating', 'N/A')})\n"
            prompt += f"- **å®‰å…¨æ€§**: æ¼æ´({measures.get('vulnerabilities', 0)}) | çƒ­ç‚¹({measures.get('security_hotspots', 0)}) | è¯„çº§({measures.get('security_rating', 'N/A')})\n"
            prompt += f"- **å¯ç»´æŠ¤æ€§**: ä»£ç å¼‚å‘³({measures.get('code_smells', 0)}) | è¯„çº§({measures.get('maintainability_rating', 'N/A')})\n"
            prompt += f"- **æµ‹è¯•è¦†ç›–ç‡**: {measures.get('coverage', 'N/A')}%\n"
            prompt += f"- **é‡å¤ä»£ç å¯†åº¦**: {measures.get('duplicated_lines_density', 'N/A')}%\n"
            
            prompt += f"\n## é—®é¢˜æ¨¡å¼åˆ†æ\n{issue_patterns}\n\n## å…·ä½“é—®é¢˜ç¤ºä¾‹\n"
            
            # æ·»åŠ ä¸€äº›å…·ä½“é—®é¢˜ç¤ºä¾‹
            critical_issues = [issue for issue in issues if issue.get('severity') in ['BLOCKER', 'CRITICAL']]
            if critical_issues:
                prompt += "### é«˜ä¼˜å…ˆçº§é—®é¢˜ç¤ºä¾‹:\n"
                for i, issue in enumerate(critical_issues[:8], 1):  # åªå±•ç¤ºå‰8ä¸ª
                    component = issue.get('component', '').split(':')[-1] if ':' in issue.get('component', '') else issue.get('component', 'N/A')
                    prompt += f"{i}. **{issue.get('severity', 'UNKNOWN')}** - {issue.get('message', 'N/A')} (æ–‡ä»¶: {component}, è¡Œ: {issue.get('line', 'N/A')})\n"
            
            # æ·»åŠ å®‰å…¨çƒ­ç‚¹ç¤ºä¾‹
            high_risk_hotspots = [hs for hs in hotspots if hs.get('vulnerabilityProbability') == 'HIGH']
            if high_risk_hotspots:
                prompt += "\n### é«˜é£é™©å®‰å…¨çƒ­ç‚¹ç¤ºä¾‹:\n"
                for i, hotspot in enumerate(high_risk_hotspots[:5], 1):  # åªå±•ç¤ºå‰5ä¸ª
                    component = hotspot.get('component', '').split(':')[-1] if ':' in hotspot.get('component', '') else hotspot.get('component', 'N/A')
                    prompt += f"{i}. **{hotspot.get('securityCategory', 'UNKNOWN')}** - {hotspot.get('message', 'N/A')} (æ–‡ä»¶: {component}, è¡Œ: {hotspot.get('line', 'N/A')})\n"
            
            prompt += f"""

## æ·±åº¦åˆ†æä»»åŠ¡
è¯·åŸºäºä»¥ä¸Šæ•°æ®æä¾›ä¸“ä¸šçš„è´¨é‡åˆ†ææŠ¥å‘Šï¼š

### 1. **æ ¹å› åˆ†æ**
- åˆ†æé—®é¢˜äº§ç”Ÿçš„æ ¹æœ¬åŸå› ï¼ˆå›¢é˜Ÿä¹ æƒ¯ã€æµç¨‹ç¼ºé™·ã€æŠ€æœ¯é€‰å‹ç­‰ï¼‰
- è¯†åˆ«é‡å¤å‡ºç°çš„é—®é¢˜æ¨¡å¼

### 2. **ä¸šåŠ¡é£é™©è¯„ä¼°** 
- ä»ä¸šåŠ¡è§’åº¦è¯„ä¼°å½“å‰é—®é¢˜å¯¹ç³»ç»Ÿç¨³å®šæ€§ã€å®‰å…¨æ€§çš„å½±å“
- é¢„æµ‹ä¸ä¿®å¤å¯èƒ½å¯¼è‡´çš„é£é™©

### 3. **è´¨é‡æ”¹è¿›è·¯çº¿å›¾**
- çŸ­æœŸä¿®å¤ä¼˜å…ˆçº§ï¼ˆ1-2å‘¨å†…å¿…é¡»è§£å†³çš„é—®é¢˜ï¼‰
- ä¸­æœŸæ”¹è¿›è®¡åˆ’ï¼ˆ1-3ä¸ªæœˆå†…çš„è´¨é‡æå‡ï¼‰
- é•¿æœŸæ¶æ„ä¼˜åŒ–å»ºè®®

### 4. **å›¢é˜Ÿåä½œå»ºè®®**
- å¼€å‘æµç¨‹æ”¹è¿›å»ºè®®ï¼ˆä»£ç å®¡æŸ¥ã€æµ‹è¯•æµç¨‹ç­‰ï¼‰
- å·¥å…·å’Œè‡ªåŠ¨åŒ–æ”¹è¿›å»ºè®®

## è¾“å‡ºè¦æ±‚
- ä½¿ç”¨ä¸­æ–‡ï¼Œä¿æŒä¸“ä¸šæ€§å’Œå®ç”¨æ€§
- é‡ç‚¹å…³æ³¨å¯æ“ä½œçš„å…·ä½“å»ºè®®
- é¿å…æ³›æ³›è€Œè°ˆï¼ŒåŸºäºå®é™…æ•°æ®åˆ†æ
- å†…å®¹æ§åˆ¶åœ¨500å­—ä»¥å†…ï¼Œæ¡ç†æ¸…æ™°
"""
            
            # è°ƒç”¨AIåˆ†æ
            try:
                self.logger.debug("å¼€å§‹è°ƒç”¨Ollama APIè¿›è¡Œç¼ºé™·åˆ†æ...")
                result = self.ollama.analyze_text(prompt, model=self.ai_model, analysis_type="custom")
                self.logger.debug("Ollama APIè°ƒç”¨æˆåŠŸ")
                return result
            except Exception as ollama_error:
                self.logger.warning(f"Ollama APIè°ƒç”¨å¤±è´¥: {ollama_error}")
                return f"AIåˆ†æä¸å¯ç”¨ï¼šOllamaæœåŠ¡å¯èƒ½æœªå¯åŠ¨æˆ–è¶…æ—¶"
            
        except Exception as e:
            self.logger.error(f"ç”ŸæˆAIåˆ†æå¤±è´¥: {e}")
            return f"åˆ†æå¤±è´¥: {str(e)}"
    
    def generate_markdown_report(self, analysis_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆä¼˜åŒ–åçš„Markdownæ ¼å¼æŠ¥å‘Š"""
        md_content = []
        
        # æ ‡é¢˜å’ŒåŸºæœ¬ä¿¡æ¯
        project_name = analysis_data['project_info']['name']
        project_key = analysis_data['project_info']['key']
        
        md_content.append(f"# ğŸ“Š SonarQubeé¡¹ç›®è´¨é‡åˆ†ææŠ¥å‘Š")
        md_content.append(f"")
        
        # æ·»åŠ SonarQubeé¡¹ç›®é“¾æ¥
        sonarqube_url = self.sonarqube.config.url
        project_url = f"{sonarqube_url}/dashboard?id={self.project_key}"
        md_content.append(f"ğŸ”— **[åœ¨SonarQubeä¸­æŸ¥çœ‹é¡¹ç›®è¯¦æƒ…]({project_url})**")
        md_content.append("")
        
        # ğŸ†• æ‰§è¡Œæ‘˜è¦ - æ–°å¢éƒ¨åˆ†
        self._add_executive_summary(md_content, analysis_data)
        
        # é¡¹ç›®åŸºæœ¬ä¿¡æ¯å¡ç‰‡
        md_content.append("## ğŸ—ï¸ é¡¹ç›®ä¿¡æ¯")
        md_content.append(f"| é¡¹ç›® | å†…å®¹ |")
        md_content.append(f"|------|------|")
        md_content.append(f"| **é¡¹ç›®åç§°** | `{project_name}` |")
        md_content.append(f"| **é¡¹ç›®æ ‡è¯†** | `{project_key}` |")
        md_content.append(f"| **ä¸Šæ¬¡åˆ†ææ—¶é—´** | `{analysis_data['project_info'].get('lastAnalysisDate', 'N/A')}` |")
        md_content.append(f"| **æŠ¥å‘Šç”Ÿæˆæ—¶é—´** | `{analysis_data['generated_at']}` |")
        md_content.append(f"")
        
        # è´¨é‡é—¨çŠ¶æ€
        summary = analysis_data['summary']
        quality_gate_status = summary['quality_gate_status']
        gate_emoji = "âœ…" if quality_gate_status == "OK" else "âŒ" if quality_gate_status == "ERROR" else "âš ï¸"
        
        md_content.append("## ğŸš¦ è´¨é‡é—¨çŠ¶æ€")
        md_content.append(f"**çŠ¶æ€**: {gate_emoji} `{quality_gate_status}`")
        
        failed_conditions = summary.get('failed_conditions', 0)
        total_conditions = summary.get('quality_gate_conditions', 0)
        if failed_conditions > 0:
            md_content.append(f"**å¤±è´¥æ¡ä»¶**: `{failed_conditions}/{total_conditions}`")
        md_content.append(f"")
        
        # ä¸šåŠ¡å½±å“è¯„ä¼° - æ–°å¢éƒ¨åˆ†
        self._add_business_impact_section(md_content, analysis_data)
        
        # é£é™©ç­‰çº§è¯„ä¼°
        risk_level = summary['risk_level']
        risk_emoji = {
            'CRITICAL': 'ğŸ”´',
            'HIGH': 'ğŸŸ ', 
            'MEDIUM': 'ğŸŸ¡',
            'LOW': 'ğŸŸ¢',
            'MINIMAL': 'âšª'
        }.get(risk_level, 'â“')
        
        md_content.append("## âš¡ é£é™©ç­‰çº§è¯„ä¼°")
        md_content.append(f"**é¡¹ç›®é£é™©ç­‰çº§**: {risk_emoji} `{risk_level}`")
        md_content.append(f"")
        
        # æ ¸å¿ƒæŒ‡æ ‡ä»ªè¡¨ç›˜
        md_content.append("## ğŸ“ˆ æ ¸å¿ƒè´¨é‡æŒ‡æ ‡")
        md_content.append("")
        key_metrics = summary['key_metrics']
        
        md_content.append(f"| æŒ‡æ ‡ | æ•°å€¼ | è¯„çº§/çŠ¶æ€ |")
        md_content.append(f"|------|------|----------|")
        md_content.append(f"| **ğŸ› Bugs** | `{key_metrics['bugs']}` | {self._get_rating_emoji(key_metrics['reliability_rating'])} {key_metrics['reliability_rating']} |")
        md_content.append(f"| **ğŸ”“ æ¼æ´** | `{key_metrics['vulnerabilities']}` | {self._get_rating_emoji(key_metrics['security_rating'])} {key_metrics['security_rating']} |")
        md_content.append(f"| **ğŸ’¨ ä»£ç å¼‚å‘³** | `{key_metrics['code_smells']}` | {self._get_rating_emoji(key_metrics['maintainability_rating'])} {key_metrics['maintainability_rating']} |")
        md_content.append(f"| **ğŸ”¥ å®‰å…¨çƒ­ç‚¹** | `{key_metrics['security_hotspots']}` | - |")
        md_content.append(f"| **ğŸ“Š æµ‹è¯•è¦†ç›–ç‡** | `{key_metrics['coverage']}`% | {'âœ…' if key_metrics['coverage'] >= 80 else 'âš ï¸' if key_metrics['coverage'] >= 60 else 'âŒ'} |")
        md_content.append(f"| **ğŸ“‹ é‡å¤ä»£ç å¯†åº¦** | `{key_metrics['duplicated_lines_density']}`% | {'âœ…' if key_metrics['duplicated_lines_density'] <= 3 else 'âš ï¸' if key_metrics['duplicated_lines_density'] <= 5 else 'âŒ'} |")
        md_content.append("")
        
        # é—®é¢˜ç»Ÿè®¡åˆ†å¸ƒ
        md_content.append("## ğŸ” é—®é¢˜åˆ†å¸ƒç»Ÿè®¡")
        
        issue_stats = summary['issue_stats']
        hotspot_stats = summary['hotspot_stats']
        
        # æŒ‰ç±»å‹ç»Ÿè®¡ - å¢å¼ºæ˜¾ç¤º
        md_content.append("### ğŸ“Š ç¼ºé™·ç±»å‹åˆ†å¸ƒ")
        md_content.append("")
        
        total_issues = issue_stats['total']
        if total_issues > 0:
            md_content.append(f"**æ€»è®¡å‘ç° `{total_issues}` ä¸ªä»£ç è´¨é‡é—®é¢˜**")
            md_content.append("")
            
            md_content.append("| ç¼ºé™·ç±»å‹ | æ•°é‡ | å æ¯” | è¯´æ˜ |")
            md_content.append("|----------|------|------|------|")
            
            # å®šä¹‰ç±»å‹è¯´æ˜
            type_descriptions = {
                'BUG': 'åŠŸèƒ½æ€§é”™è¯¯ï¼Œå¯èƒ½å¯¼è‡´ç¨‹åºå¼‚å¸¸æˆ–ç»“æœé”™è¯¯',
                'VULNERABILITY': 'å®‰å…¨æ¼æ´ï¼Œå­˜åœ¨è¢«æ¶æ„åˆ©ç”¨çš„é£é™©', 
                'CODE_SMELL': 'ä»£ç å¼‚å‘³ï¼Œå½±å“ä»£ç å¯è¯»æ€§å’Œç»´æŠ¤æ€§'
            }
            
            # æŒ‰é‡è¦æ€§æ’åºæ˜¾ç¤º
            type_order = ['BUG', 'VULNERABILITY', 'CODE_SMELL']
            for issue_type in type_order:
                count = issue_stats['by_type'].get(issue_type, 0)
                if count > 0:
                    percentage = (count / total_issues * 100)
                    type_emoji = {'BUG': 'ğŸ›', 'VULNERABILITY': 'ğŸ”“', 'CODE_SMELL': 'ğŸ’¨'}.get(issue_type, 'â“')
                    description = type_descriptions.get(issue_type, '')
                    md_content.append(f"| {type_emoji} **{issue_type}** | `{count}` | `{percentage:.1f}%` | {description} |")
        else:
            md_content.append("âœ… **æœªå‘ç°ä»£ç è´¨é‡é—®é¢˜**")
        
        md_content.append("")
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡
        md_content.append("### ğŸš¨ æŒ‰ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡")
        md_content.append(f"| ä¸¥é‡ç¨‹åº¦ | æ•°é‡ | ä¼˜å…ˆçº§ |")
        md_content.append(f"|----------|------|--------|")
        
        severity_order = ['BLOCKER', 'CRITICAL', 'MAJOR', 'MINOR', 'INFO']
        for severity in severity_order:
            count = issue_stats['by_severity'].get(severity, 0)
            if count > 0:
                severity_emoji = {
                    'BLOCKER': 'ğŸ”´',
                    'CRITICAL': 'ğŸŸ ', 
                    'MAJOR': 'ğŸŸ¡',
                    'MINOR': 'ğŸ”µ',
                    'INFO': 'âšª'
                }.get(severity, 'â“')
                priority = {
                    'BLOCKER': 'ç«‹å³å¤„ç†',
                    'CRITICAL': 'é«˜ä¼˜å…ˆçº§',
                    'MAJOR': 'ä¸­ä¼˜å…ˆçº§', 
                    'MINOR': 'ä½ä¼˜å…ˆçº§',
                    'INFO': 'ä¿¡æ¯'
                }.get(severity, 'æœªçŸ¥')
                md_content.append(f"| {severity_emoji} {severity} | `{count}` | {priority} |")
        md_content.append("")
        
        # å®‰å…¨çƒ­ç‚¹ç»Ÿè®¡  
        if hotspot_stats['total'] > 0:
            md_content.append("### ğŸ”¥ å®‰å…¨çƒ­ç‚¹ç»Ÿè®¡")
            md_content.append(f"**æ€»è®¡**: `{hotspot_stats['total']}` ä¸ª")
            md_content.append("")
            
            # æŒ‰é£é™©æ¦‚ç‡ç»Ÿè®¡
            md_content.append(f"| é£é™©æ¦‚ç‡ | æ•°é‡ | å¤„ç†å»ºè®® |")
            md_content.append(f"|----------|------|----------|")
            
            prob_order = ['HIGH', 'MEDIUM', 'LOW']
            for prob in prob_order:
                count = hotspot_stats['by_vulnerability_probability'].get(prob, 0)
                if count > 0:
                    prob_emoji = {'HIGH': 'ğŸ”´', 'MEDIUM': 'ğŸŸ¡', 'LOW': 'ğŸŸ¢'}.get(prob, 'â“')
                    suggestion = {'HIGH': 'ç«‹å³å®¡æŸ¥', 'MEDIUM': 'åŠæ—¶å®¡æŸ¥', 'LOW': 'å®šæœŸå®¡æŸ¥'}.get(prob, 'å®¡æŸ¥')
                    md_content.append(f"| {prob_emoji} {prob} | `{count}` | {suggestion} |")
            md_content.append("")
        
        # AIæ™ºèƒ½åˆ†æ
        if analysis_data['ai_analysis']:
            md_content.append("## ğŸ¤– AIæ™ºèƒ½åˆ†æ")
            md_content.append("")
            md_content.append("> ğŸ§  **åŸºäºé¡¹ç›®è´¨é‡æ•°æ®çš„æ™ºèƒ½æ´å¯Ÿ**")
            md_content.append("")
            
            # å°†AIåˆ†ææ ¼å¼åŒ–ä¸ºå¼•ç”¨å—
            ai_lines = analysis_data['ai_analysis'].split('\n')
            for line in ai_lines:
                if line.strip():
                    if line.startswith('###') or line.startswith('**'):
                        md_content.append(f"> {line}")
                    else:
                        md_content.append(f"> {line}")
                else:
                    md_content.append(">")
            
            md_content.append("")
            md_content.append("> ğŸ’¡ *ä»¥ä¸Šåˆ†æåŸºäºSonarQubeæ•°æ®å’Œä»£ç è´¨é‡æ¨¡å¼ç”Ÿæˆ*")
            md_content.append("")
        
        # é—®é¢˜è¯¦æƒ…
        self._add_issue_details_section(md_content, analysis_data)
        
        # åŠ¡å®çš„ä¿®å¤å»ºè®®
        self._add_practical_recommendations(md_content, analysis_data)
        
        # ğŸ†• ä¿®å¤ä¼˜å…ˆçº§çŸ©é˜µ - æ›¿æ¢åŸæœ‰çš„ä¿®å¤å»ºè®®
        self._add_priority_matrix_section(md_content, analysis_data)
        
        # é™„å½•
        md_content.append("## ğŸ“‹ é™„å½•")
        md_content.append("")
        md_content.append("### åˆ†æè¯´æ˜")
        md_content.append("- æœ¬æŠ¥å‘ŠåŸºäºSonarQubeé™æ€ä»£ç åˆ†ææ•°æ®ç”Ÿæˆ")
        
        actual_total = issue_stats.get('total', len(analysis_data['issues']['raw_data']))
        sampled_total = issue_stats.get('sampled_total', len(analysis_data['issues']['raw_data']))
        is_sampled = issue_stats.get('sampled', False)
        
        if is_sampled:
            md_content.append(f"- **é¡¹ç›®å®é™…ç¼ºé™·**: `{actual_total}` ä¸ªä»£ç è´¨é‡é—®é¢˜")
            md_content.append(f"- **æ™ºèƒ½é‡‡æ ·åˆ†æ**: `{sampled_total}` ä¸ªé—®é¢˜ç”¨äºè¯¦ç»†åˆ†æ")
            md_content.append("- âš ï¸ **å¤§æ•°æ®é‡é‡‡æ ·ç­–ç•¥**:")
            md_content.append("  - ğŸ”´ BLOCKER/CRITICALé—®é¢˜: 100% å…¨é‡åˆ†æ")
            md_content.append("  - ğŸŸ¡ MAJORé—®é¢˜: 30% åˆ†å±‚é‡‡æ ·")
            md_content.append("  - ğŸŸ¢ MINOR/INFOé—®é¢˜: 10% ä»£è¡¨æ€§é‡‡æ ·")
        else:
            md_content.append(f"- **åˆ†æé—®é¢˜æ•°é‡**: `{actual_total}` ä¸ªä»£ç è´¨é‡é—®é¢˜")
            
        md_content.append(f"- æ£€æŸ¥äº† `{hotspot_stats['total']}` ä¸ªå®‰å…¨çƒ­ç‚¹")
        
        # æ·»åŠ AIæ¨¡å‹ä¿¡æ¯
        ai_model_info = analysis_data.get('ai_model_info', {})
        if ai_model_info.get('enabled'):
            ai_model = ai_model_info.get('model', 'æœªçŸ¥æ¨¡å‹')
            md_content.append(f"- AIåˆ†æåŸºäºOllamaæœ¬åœ°æ¨¡å‹ç”Ÿæˆï¼Œä½¿ç”¨æ¨¡å‹: **{ai_model}**")
        else:
            md_content.append("- æœ¬æ¬¡åˆ†ææœªå¯ç”¨AIåŠŸèƒ½")
        
        md_content.append("")
        
        # æ·»åŠ SonarQubeé¡¹ç›®é“¾æ¥
        md_content.append("### ğŸ”— æŸ¥çœ‹è¯¦æƒ…")
        sonarqube_url = self.sonarqube.config.url
        project_url = f"{sonarqube_url}/dashboard?id={self.project_key}"
        md_content.append(f"ğŸ“Š [åœ¨SonarQubeä¸­æŸ¥çœ‹å®Œæ•´é¡¹ç›®åˆ†æ]({project_url})")
        md_content.append("")
        
        return "\n".join(md_content)
    
    def _add_executive_summary(self, md_content: list, analysis_data: dict):
        """æ·»åŠ æ‰§è¡Œæ‘˜è¦éƒ¨åˆ†"""
        md_content.append("## ğŸ“‹ æ‰§è¡Œæ‘˜è¦")
        md_content.append("")
        
        summary = analysis_data['summary']
        issue_stats = summary['issue_stats']
        risk_level = summary['risk_level']
        total_issues = issue_stats['total']
        critical_issues = issue_stats['by_severity'].get('BLOCKER', 0) + issue_stats['by_severity'].get('CRITICAL', 0)
        
        # æ•´ä½“è¯„çº§
        risk_emoji = {
            'CRITICAL': 'ğŸ”´',
            'HIGH': 'ğŸŸ ', 
            'MEDIUM': 'ğŸŸ¡',
            'LOW': 'ğŸŸ¢',
            'MINIMAL': 'âšª'
        }.get(risk_level, 'â“')
        
        md_content.append(f"### ğŸ¯ å…³é”®å‘ç°")
        md_content.append(f"- **æ•´ä½“é£é™©ç­‰çº§**: {risk_emoji} **{risk_level}**")
        
        # æ˜¾ç¤ºå®é™…æ•°é‡å’Œé‡‡æ ·æ•°é‡
        actual_total = issue_stats.get('total', total_issues)
        sampled_total = issue_stats.get('sampled_total', len(analysis_data['issues']['raw_data']))
        is_sampled = issue_stats.get('sampled', False)
        
        if is_sampled:
            md_content.append(f"- **å®é™…ç¼ºé™·æ€»æ•°**: **{actual_total}** ä¸ªä»£ç è´¨é‡é—®é¢˜")
            md_content.append(f"- **æ™ºèƒ½é‡‡æ ·åˆ†æ**: **{sampled_total}** ä¸ªé—®é¢˜ (é«˜ä¼˜å…ˆçº§100%ä¿ç•™)")
        else:
            md_content.append(f"- **å‘ç°é—®é¢˜æ€»æ•°**: **{actual_total}** ä¸ªä»£ç è´¨é‡é—®é¢˜")
        
        if critical_issues > 0:
            md_content.append(f"- **ç´§æ€¥é—®é¢˜**: **{critical_issues}** ä¸ªä¸¥é‡ç¼ºé™·éœ€è¦ç«‹å³å¤„ç†")
        else:
            md_content.append("- **ç´§æ€¥é—®é¢˜**: âœ… æ— ä¸¥é‡é˜»å¡æ€§é—®é¢˜")
        
        # ä¸šåŠ¡å½±å“å¿«é€Ÿè¯„ä¼°
        md_content.append("")
        md_content.append("### ğŸ’¼ ä¸šåŠ¡å½±å“å¿«é€Ÿè¯„ä¼°")
        
        vulnerabilities = issue_stats['by_type'].get('VULNERABILITY', 0)
        bugs = issue_stats['by_type'].get('BUG', 0)
        code_smells = issue_stats['by_type'].get('CODE_SMELL', 0)
        
        if vulnerabilities > 0:
            md_content.append(f"- **å®‰å…¨é£é™©**: ğŸ”´ **é«˜** - å‘ç° **{vulnerabilities}** ä¸ªå®‰å…¨æ¼æ´ï¼Œå­˜åœ¨æ•°æ®æ³„éœ²é£é™©")
        else:
            md_content.append("- **å®‰å…¨é£é™©**: ğŸŸ¢ **ä½** - æœªå‘ç°å®‰å…¨æ¼æ´")
            
        if bugs > 0:
            md_content.append(f"- **åŠŸèƒ½é£é™©**: {'ğŸ”´ **é«˜**' if bugs > 10 else 'ğŸŸ¡ **ä¸­**'} - **{bugs}** ä¸ªåŠŸèƒ½ç¼ºé™·å¯èƒ½å½±å“ç”¨æˆ·ä½“éªŒ")
        else:
            md_content.append("- **åŠŸèƒ½é£é™©**: ğŸŸ¢ **ä½** - æœªå‘ç°åŠŸèƒ½æ€§ç¼ºé™·")
            
        if code_smells > 20:
            md_content.append(f"- **ç»´æŠ¤é£é™©**: ğŸŸ¡ **ä¸­** - **{code_smells}** ä¸ªä»£ç å¼‚å‘³å½±å“é•¿æœŸç»´æŠ¤")
        elif code_smells > 0:
            md_content.append(f"- **ç»´æŠ¤é£é™©**: ğŸŸ¢ **ä½** - **{code_smells}** ä¸ªä»£ç å¼‚å‘³ï¼Œæ•´ä½“å¯æ§")
        else:
            md_content.append("- **ç»´æŠ¤é£é™©**: ğŸŸ¢ **ä½** - ä»£ç è´¨é‡è‰¯å¥½")
        
        # è¡ŒåŠ¨å»ºè®®
        md_content.append("")
        md_content.append("### âš¡ ç«‹å³è¡ŒåŠ¨å»ºè®®")
        
        if critical_issues > 0:
            days_needed = min(7, max(1, critical_issues // 2 + 1))
            md_content.append(f"- ğŸš¨ **ç´§æ€¥ä¿®å¤**: **{days_needed}** å¤©å†…å®Œæˆæ‰€æœ‰ä¸¥é‡é—®é¢˜ä¿®å¤")
            
        if vulnerabilities > 0:
            md_content.append("- ğŸ›¡ï¸ **å®‰å…¨ä¼˜å…ˆ**: ç«‹å³å®¡æŸ¥æ‰€æœ‰å®‰å…¨æ¼æ´ï¼Œä¼˜å…ˆä¿®å¤é«˜é£é™©é¡¹")
            
        # èµ„æºæŠ•å…¥å»ºè®®
        team_size = self._recommend_team_size(total_issues)
        estimated_hours = self._estimate_fix_time(issue_stats['by_severity'], total_issues)
        
        md_content.append(f"- ğŸ’° **èµ„æºé…ç½®**: å»ºè®®æŠ•å…¥ **{team_size}** åå¼€å‘äººå‘˜ï¼Œé¢„è®¡ **{estimated_hours}** å·¥æ—¶")
        
        md_content.append("")
        md_content.append("---")
        md_content.append("")
    
    def _add_business_impact_section(self, md_content: list, analysis_data: dict):
        """æ·»åŠ ä¸šåŠ¡å½±å“è¯„ä¼°éƒ¨åˆ†"""
        md_content.append("## ğŸ’¼ ä¸šåŠ¡å½±å“è¯„ä¼°")
        md_content.append("")
        
        issue_stats = analysis_data['summary']['issue_stats']
        measures = analysis_data.get('measures', {})
        
        # è®¡ç®—æ€§èƒ½ç›¸å…³é—®é¢˜
        performance_issues = 0
        memory_issues = 0
        
        for issue in analysis_data['issues']['raw_data']:
            if isinstance(issue, dict):
                rule = issue.get('rule', '').lower()
                message = issue.get('message', '').lower()
                
                if any(keyword in rule or keyword in message for keyword in ['performance', 'memory', 'resource', 'timeout']):
                    performance_issues += 1
                if any(keyword in rule or keyword in message for keyword in ['memory', 'leak', 'heap']):
                    memory_issues += 1
        
        md_content.append("| å½±å“ç»´åº¦ | é£é™©ç­‰çº§ | è¯¦ç»†è¯´æ˜ | å»ºè®®æªæ–½ |")
        md_content.append("|----------|----------|----------|----------|")
        
        # ç”¨æˆ·ä½“éªŒå½±å“
        ux_risk = "ğŸ”´ é«˜" if performance_issues > 5 else "ğŸŸ¡ ä¸­" if performance_issues > 2 else "ğŸŸ¢ ä½"
        ux_desc = f"{performance_issues}ä¸ªæ€§èƒ½é—®é¢˜" + ("å¯èƒ½å¯¼è‡´å“åº”å»¶è¿Ÿ" if performance_issues > 0 else "")
        ux_action = "ç«‹å³ä¼˜åŒ–å…³é”®è·¯å¾„" if performance_issues > 5 else "ç›‘æ§æ€§èƒ½æŒ‡æ ‡" if performance_issues > 0 else "ç»´æŒç°çŠ¶"
        md_content.append(f"| **ç”¨æˆ·ä½“éªŒ** | {ux_risk} | {ux_desc} | {ux_action} |")
        
        # æ•°æ®å®‰å…¨å½±å“
        vuln_count = issue_stats['by_type'].get('VULNERABILITY', 0)
        security_risk = "ğŸ”´ é«˜" if vuln_count > 3 else "ğŸŸ¡ ä¸­" if vuln_count > 0 else "ğŸŸ¢ ä½"
        security_desc = f"{vuln_count}ä¸ªå®‰å…¨æ¼æ´" if vuln_count > 0 else "æœªå‘ç°å®‰å…¨é£é™©"
        security_action = "ç«‹å³ä¿®å¤æ‰€æœ‰æ¼æ´" if vuln_count > 3 else "å°½å¿«ä¿®å¤" if vuln_count > 0 else "åŠ å¼ºå®‰å…¨æ£€æµ‹"
        md_content.append(f"| **æ•°æ®å®‰å…¨** | {security_risk} | {security_desc} | {security_action} |")
        
        # ç³»ç»Ÿç¨³å®šæ€§å½±å“
        bugs = issue_stats['by_type'].get('BUG', 0)
        stability_risk = "ğŸ”´ é«˜" if bugs > 10 else "ğŸŸ¡ ä¸­" if bugs > 3 else "ğŸŸ¢ ä½"
        stability_desc = f"{bugs}ä¸ªåŠŸèƒ½ç¼ºé™·"
        if memory_issues > 0:
            stability_desc += f"ï¼Œ{memory_issues}ä¸ªå†…å­˜é—®é¢˜"
        stability_action = "ç´§æ€¥ä¿®å¤æ ¸å¿ƒç¼ºé™·" if bugs > 10 else "æŒ‰ä¼˜å…ˆçº§ä¿®å¤" if bugs > 0 else "ä¿æŒç›‘æ§"
        md_content.append(f"| **ç³»ç»Ÿç¨³å®šæ€§** | {stability_risk} | {stability_desc} | {stability_action} |")
        
        # åˆè§„æ€§å½±å“
        coverage = measures.get('coverage', 0)
        compliance_risk = "ğŸŸ¡ ä¸­" if coverage < 50 else "ğŸŸ¢ ä½"
        compliance_desc = f"æµ‹è¯•è¦†ç›–ç‡{coverage:.1f}%" + ("ï¼Œå¯èƒ½å½±å“å®¡è®¡" if coverage < 50 else "ï¼Œç¬¦åˆæ ‡å‡†")
        compliance_action = "æå‡æµ‹è¯•è¦†ç›–ç‡" if coverage < 50 else "ç»´æŒè´¨é‡æ ‡å‡†"
        md_content.append(f"| **åˆè§„æ€§** | {compliance_risk} | {compliance_desc} | {compliance_action} |")
        
        md_content.append("")
    
    def _recommend_team_size(self, total_issues: int) -> int:
        """æ ¹æ®é—®é¢˜æ•°é‡æ¨èå›¢é˜Ÿè§„æ¨¡"""
        if total_issues > 50:
            return 3
        elif total_issues > 20:
            return 2
        else:
            return 1
    
    def _estimate_fix_time(self, severity_stats: dict, _: int) -> int:
        """ä¼°ç®—ä¿®å¤æ—¶é—´ï¼ˆå°æ—¶ï¼‰"""
        blocker_hours = severity_stats.get('BLOCKER', 0) * 4
        critical_hours = severity_stats.get('CRITICAL', 0) * 2
        major_hours = severity_stats.get('MAJOR', 0) * 1
        minor_hours = severity_stats.get('MINOR', 0) * 0.5
        
        total_hours = blocker_hours + critical_hours + major_hours + minor_hours
        return int(max(8, total_hours))  # æœ€å°‘8å°æ—¶
    
    def _add_priority_matrix_section(self, md_content: list, analysis_data: dict):
        """æ·»åŠ ä¿®å¤ä¼˜å…ˆçº§çŸ©é˜µéƒ¨åˆ†"""
        md_content.append("## ğŸ¯ ä¿®å¤ä¼˜å…ˆçº§çŸ©é˜µ")
        md_content.append("")
        
        issues = analysis_data['issues']['raw_data']
        
        # æŒ‰ä¼˜å…ˆçº§åˆ†ç±»é—®é¢˜
        priority_groups = {
            'P0': [],  # å®‰å…¨æ¼æ´å’Œé˜»å¡æ€§é—®é¢˜
            'P1': [],  # ä¸¥é‡åŠŸèƒ½é—®é¢˜
            'P2': [],  # é‡è¦è´¨é‡é—®é¢˜
            'P3': []   # ä¸€èˆ¬æ”¹è¿›é¡¹
        }
        
        for issue in issues:
            if isinstance(issue, dict):
                severity = issue.get('severity', '')
                issue_type = issue.get('type', '')
                
                if issue_type == 'VULNERABILITY' or severity == 'BLOCKER':
                    priority_groups['P0'].append(issue)
                elif severity == 'CRITICAL' or (issue_type == 'BUG' and severity == 'MAJOR'):
                    priority_groups['P1'].append(issue)
                elif severity == 'MAJOR':
                    priority_groups['P2'].append(issue)
                else:
                    priority_groups['P3'].append(issue)
        
        md_content.append("| ä¼˜å…ˆçº§ | é—®é¢˜ç±»å‹ | æ•°é‡ | ä¸šåŠ¡å½±å“ | å»ºè®®å®Œæˆæ—¶é—´ |")
        md_content.append("|--------|----------|------|----------|-------------|")
        
        if len(priority_groups['P0']) > 0:
            md_content.append(f"| ğŸš¨ **P0** | å®‰å…¨æ¼æ´/é˜»å¡é—®é¢˜ | **{len(priority_groups['P0'])}** | æ•°æ®æ³„éœ²/ç³»ç»Ÿå´©æºƒ | **ç«‹å³ä¿®å¤** (1-2å¤©) |")
            
        if len(priority_groups['P1']) > 0:
            md_content.append(f"| ğŸ”´ **P1** | ä¸¥é‡åŠŸèƒ½ç¼ºé™· | **{len(priority_groups['P1'])}** | å½±å“æ ¸å¿ƒä¸šåŠ¡æµç¨‹ | **æœ¬å‘¨å†…** (3-5å¤©) |")
            
        if len(priority_groups['P2']) > 0:
            md_content.append(f"| ğŸŸ¡ **P2** | é‡è¦è´¨é‡é—®é¢˜ | **{len(priority_groups['P2'])}** | å½±å“ç”¨æˆ·ä½“éªŒ | **2å‘¨å†…** |")
            
        if len(priority_groups['P3']) > 0:
            md_content.append(f"| ğŸŸ¢ **P3** | ä»£ç è´¨é‡æ”¹è¿› | **{len(priority_groups['P3'])}** | é•¿æœŸç»´æŠ¤æ€§ | **1ä¸ªæœˆå†…** |")
        
        md_content.append("")
        
        # æ·»åŠ å…·ä½“çš„P0é—®é¢˜åˆ—è¡¨ï¼ˆå¦‚æœæœ‰ï¼‰
        if len(priority_groups['P0']) > 0:
            md_content.append("### ğŸš¨ P0çº§é—®é¢˜è¯¦æƒ… (éœ€ç«‹å³å¤„ç†)")
            md_content.append("")
            
            for i, issue in enumerate(priority_groups['P0'][:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
                component = issue.get('component', '').split(':')[-1]
                line = issue.get('line', 'N/A')
                message = issue.get('message', 'æ— æè¿°')[:80] + ('...' if len(issue.get('message', '')) > 80 else '')
                
                md_content.append(f"**{i}.** `{component}:{line}` - {message}")
            
            if len(priority_groups['P0']) > 10:
                md_content.append(f"... è¿˜æœ‰ {len(priority_groups['P0']) - 10} ä¸ªP0é—®é¢˜ï¼Œè¯¦è§å®Œæ•´æŠ¥å‘Š")
            
            md_content.append("")
        
        # æ·»åŠ ä»£ç ä¿®å¤ç¤ºä¾‹ï¼ˆä¸ºé«˜ä¼˜å…ˆçº§é—®é¢˜ï¼‰
        self._add_code_fix_examples(md_content, priority_groups)
    
    def _add_code_fix_examples(self, md_content: list, priority_groups: dict):
        """æ·»åŠ ä»£ç ä¿®å¤ç¤ºä¾‹"""
        critical_issues = priority_groups['P0'] + priority_groups['P1']
        
        if len(critical_issues) > 0:
            md_content.append("### ğŸ”§ å…³é”®é—®é¢˜ä¿®å¤ç¤ºä¾‹")
            md_content.append("")
            
            examples_shown = 0
            for issue in critical_issues[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªç¤ºä¾‹
                rule = issue.get('rule', '')
                message = issue.get('message', '')
                component = issue.get('component', '').split(':')[-1]
                line = issue.get('line', 'N/A')
                
                # ç”Ÿæˆä¿®å¤ç¤ºä¾‹
                fix_example = self._generate_fix_example(rule, message)
                if fix_example:
                    examples_shown += 1
                    md_content.append(f"#### ç¤ºä¾‹ {examples_shown}: {component}:{line}")
                    md_content.append(f"**é—®é¢˜**: {message}")
                    md_content.append("")
                    md_content.append(fix_example)
                    md_content.append("")
                    
                if examples_shown >= 3:  # æœ€å¤šæ˜¾ç¤º3ä¸ªç¤ºä¾‹
                    break
            
            if examples_shown == 0:
                md_content.append("å…·ä½“ä¿®å¤å»ºè®®è¯·å‚è€ƒSonarQubeè§„åˆ™æ–‡æ¡£ã€‚")
                md_content.append("")
    
    def _generate_fix_example(self, rule: str, message: str) -> str:
        """ç”Ÿæˆå…·ä½“çš„ä¿®å¤ç¤ºä¾‹"""
        # å¸¸è§çš„ä¿®å¤ç¤ºä¾‹æ¨¡æ¿
        fix_templates = {
            'java:S1172': {
                'description': 'ç§»é™¤æœªä½¿ç”¨çš„æ–¹æ³•å‚æ•°',
                'before': '''```java
// âŒ å½“å‰ä»£ç  (å­˜åœ¨æœªä½¿ç”¨å‚æ•°)
public void processData(String data, int unusedParam) {
    System.out.println(data);
}
```''',
                'after': '''```java
// âœ… ä¿®å¤åä»£ç  (ç§»é™¤æœªä½¿ç”¨å‚æ•°)
public void processData(String data) {
    System.out.println(data);
}
```'''
            },
            'java:S2095': {
                'description': 'ç¡®ä¿èµ„æºæ­£ç¡®å…³é—­',
                'before': '''```java
// âŒ å½“å‰ä»£ç  (èµ„æºæœªå…³é—­)
FileInputStream fis = new FileInputStream("file.txt");
// ... ä½¿ç”¨èµ„æºä½†æœªå…³é—­
```''',
                'after': '''```java
// âœ… ä¿®å¤åä»£ç  (ä½¿ç”¨try-with-resources)
try (FileInputStream fis = new FileInputStream("file.txt")) {
    // ... ä½¿ç”¨èµ„æºï¼Œè‡ªåŠ¨å…³é—­
}
```'''
            },
            'java:S1118': {
                'description': 'å·¥å…·ç±»åº”è¯¥æœ‰ç§æœ‰æ„é€ å‡½æ•°',
                'before': '''```java
// âŒ å½“å‰ä»£ç  (å…¬å…±æ„é€ å‡½æ•°)
public class Utils {
    public static String format(String text) {
        return text.trim();
    }
}
```''',
                'after': '''```java
// âœ… ä¿®å¤åä»£ç  (ç§æœ‰æ„é€ å‡½æ•°)
public class Utils {
    private Utils() {
        // é˜²æ­¢å®ä¾‹åŒ–
    }
    
    public static String format(String text) {
        return text.trim();
    }
}
```'''
            }
        }
        
        if rule in fix_templates:
            template = fix_templates[rule]
            return f"**è§£å†³æ–¹æ¡ˆ**: {template['description']}\n\n{template['before']}\n\n{template['after']}"
        
        # å¯¹äºæ²¡æœ‰ç‰¹å®šæ¨¡æ¿çš„è§„åˆ™ï¼Œè¿”å›é€šç”¨å»ºè®®
        if 'unused' in message.lower():
            return "**è§£å†³æ–¹æ¡ˆ**: ç§»é™¤æœªä½¿ç”¨çš„ä»£ç å…ƒç´ ä»¥æé«˜ä»£ç æ¸…æ´åº¦ã€‚"
        elif 'null' in message.lower():
            return "**è§£å†³æ–¹æ¡ˆ**: æ·»åŠ ç©ºå€¼æ£€æŸ¥æˆ–ä½¿ç”¨Optionalæ¥é¿å…NullPointerExceptionã€‚"
        elif 'security' in message.lower() or 'vulnerability' in message.lower():
            return "**è§£å†³æ–¹æ¡ˆ**: è¯·ç«‹å³å®¡æŸ¥æ­¤å®‰å…¨é—®é¢˜ï¼Œè€ƒè™‘ä½¿ç”¨å®‰å…¨çš„APIæˆ–æ·»åŠ é€‚å½“çš„éªŒè¯ã€‚"
        
        return None
        
    def _analyze_issue_patterns_for_ai(self, issues: list) -> str:
        """ä¸ºAIåˆ†æç”Ÿæˆé—®é¢˜æ¨¡å¼ä¿¡æ¯"""
        if not issues:
            return "æ— é—®é¢˜æ•°æ®"
            
        # ç»Ÿè®¡è§„åˆ™åˆ†å¸ƒ
        rule_count = {}
        component_count = {}
        
        for issue in issues:
            if isinstance(issue, dict):
                rule = issue.get('rule', 'unknown')
                component = issue.get('component', '').split(':')[-1]
                
                rule_count[rule] = rule_count.get(rule, 0) + 1
                if component:
                    component_count[component] = component_count.get(component, 0) + 1
        
        # æ‰¾å‡ºé«˜é¢‘é—®é¢˜
        top_rules = sorted(rule_count.items(), key=lambda x: x[1], reverse=True)[:3]
        top_files = sorted(component_count.items(), key=lambda x: x[1], reverse=True)[:3]
        
        patterns = []
        if top_rules:
            patterns.append("**é«˜é¢‘è§„åˆ™**: " + ", ".join([f"{rule}({count}æ¬¡)" for rule, count in top_rules]))
        if top_files:
            patterns.append("**é—®é¢˜é›†ä¸­**: " + ", ".join([f"{file}({count}é—®é¢˜)" for file, count in top_files]))
        
        return "\n".join(patterns) if patterns else "é—®é¢˜åˆ†å¸ƒè¾ƒä¸ºå‡åŒ€"
        
    def _calculate_quality_score_for_ai(self, measures: dict, severity_stats: dict) -> int:
        """ä¸ºAIåˆ†æè®¡ç®—ç»¼åˆè´¨é‡è¯„åˆ† (0-100)"""
        score = 100
        
        # è¦†ç›–ç‡å½±å“ (æœ€å¤šæ‰£30åˆ†)
        coverage = measures.get('coverage', 0)
        if coverage < 50:
            score -= 30
        elif coverage < 70:
            score -= 15
        elif coverage < 80:
            score -= 5
        
        # é‡å¤ä»£ç å½±å“ (æœ€å¤šæ‰£15åˆ†)
        duplicated = measures.get('duplicated_lines_density', 0)
        if duplicated > 10:
            score -= 15
        elif duplicated > 5:
            score -= 10
        elif duplicated > 3:
            score -= 5
        
        # ä¸¥é‡é—®é¢˜å½±å“ (æœ€å¤šæ‰£40åˆ†)
        blocker = len(severity_stats.get('BLOCKER', []))
        critical = len(severity_stats.get('CRITICAL', []))
        major = len(severity_stats.get('MAJOR', []))
        
        score -= min(40, blocker * 10 + critical * 5 + major * 2)
        
        # æŠ€æœ¯å€ºåŠ¡å½±å“ (æœ€å¤šæ‰£15åˆ†)
        debt_ratio = measures.get('sqale_debt_ratio', 0)
        if debt_ratio > 20:
            score -= 15
        elif debt_ratio > 10:
            score -= 10
        elif debt_ratio > 5:
            score -= 5
        
        return max(0, score)
    
    def _manual_sampling(self, issues: list, max_count: int) -> list:
        """æ‰‹åŠ¨é‡‡æ ·å¤„ç†å¤§é‡é—®é¢˜ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬å®¢æˆ·ç«¯ï¼‰"""
        if len(issues) <= max_count:
            return issues
            
        self.logger.warning(f"âš ï¸ é—®é¢˜æ•°é‡è¿‡å¤š({len(issues)} > {max_count})ï¼Œå¯ç”¨æ‰‹åŠ¨é‡‡æ ·")
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„
        severity_groups = {
            'BLOCKER': [],
            'CRITICAL': [],
            'MAJOR': [],
            'MINOR': [],
            'INFO': []
        }
        
        for issue in issues:
            if isinstance(issue, dict):
                severity = issue.get('severity', 'INFO')
                if severity in severity_groups:
                    severity_groups[severity].append(issue)
        
        # é‡‡æ ·ç­–ç•¥
        sampled = []
        
        # 1. æ‰€æœ‰BLOCKERå’ŒCRITICALé—®é¢˜
        sampled.extend(severity_groups['BLOCKER'])
        sampled.extend(severity_groups['CRITICAL'])
        self.logger.info(f"ğŸ”´ ä¿ç•™æ‰€æœ‰é«˜ä¼˜å…ˆçº§é—®é¢˜: {len(sampled)}ä¸ª")
        
        remaining_budget = max_count - len(sampled)
        if remaining_budget <= 0:
            return sampled[:max_count]
        
        # 2. 30%çš„MAJORé—®é¢˜
        major_count = min(len(severity_groups['MAJOR']), max(int(len(severity_groups['MAJOR']) * 0.3), 50))
        major_count = min(major_count, remaining_budget)
        if major_count > 0:
            step = max(1, len(severity_groups['MAJOR']) // major_count)
            major_sampled = severity_groups['MAJOR'][::step][:major_count]
            sampled.extend(major_sampled)
            self.logger.info(f"ğŸŸ¡ MAJORé—®é¢˜é‡‡æ ·: {len(major_sampled)}/{len(severity_groups['MAJOR'])}ä¸ª")
        
        remaining_budget = max_count - len(sampled)
        if remaining_budget <= 0:
            return sampled
        
        # 3. 10%çš„MINORé—®é¢˜
        minor_issues = severity_groups['MINOR'] + severity_groups['INFO']
        minor_count = min(len(minor_issues), max(int(len(minor_issues) * 0.1), remaining_budget))
        if minor_count > 0:
            step = max(1, len(minor_issues) // minor_count)
            minor_sampled = minor_issues[::step][:minor_count]
            sampled.extend(minor_sampled)
            self.logger.info(f"ğŸŸ¢ MINOR/INFOé—®é¢˜é‡‡æ ·: {len(minor_sampled)}/{len(minor_issues)}ä¸ª")
        
        self.logger.info(f"âœ… æ‰‹åŠ¨é‡‡æ ·å®Œæˆ: {len(sampled)}/{len(issues)} ä¸ªé—®é¢˜")
        return sampled[:max_count]
    
    def _add_issue_details_section(self, md_content: list, analysis_data: dict):
        """æ·»åŠ é—®é¢˜è¯¦æƒ…éƒ¨åˆ†"""
        md_content.append("## ğŸ“‹ é—®é¢˜è¯¦æƒ…")
        md_content.append("")
        
        issues = analysis_data['issues']['raw_data']
        if not issues:
            md_content.append("âœ… æœªå‘ç°ä»£ç è´¨é‡é—®é¢˜ã€‚")
            md_content.append("")
            return
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦æ’åºï¼Œè·å–å‰20ä¸ªä¸åŒç±»å‹çš„é—®é¢˜
        severity_order = ['BLOCKER', 'CRITICAL', 'MAJOR', 'MINOR', 'INFO']
        type_order = ['BUG', 'VULNERABILITY', 'CODE_SMELL']
        
        # åˆ†ç±»æ”¶é›†é—®é¢˜
        categorized_issues = {}
        for severity in severity_order:
            categorized_issues[severity] = {}
            for issue_type in type_order:
                categorized_issues[severity][issue_type] = []
        
        # åˆ†ç±»æ‰€æœ‰é—®é¢˜
        for issue in issues:
            if isinstance(issue, dict):
                severity = issue.get('severity', 'UNKNOWN')
                issue_type = issue.get('type', 'UNKNOWN')
                if severity in categorized_issues and issue_type in categorized_issues[severity]:
                    categorized_issues[severity][issue_type].append(issue)
        
        # é€‰æ‹©å‰20ä¸ªæœ€é‡è¦çš„é—®é¢˜
        selected_issues = []
        for severity in severity_order:
            for issue_type in type_order:
                issues_of_type = categorized_issues[severity][issue_type]
                if issues_of_type and len(selected_issues) < 20:
                    # æ¯ç§ç±»å‹æœ€å¤šå–4ä¸ª
                    for issue in issues_of_type[:4]:
                        if len(selected_issues) < 20:
                            selected_issues.append(issue)
        
        if not selected_issues:
            md_content.append("âœ… æœªå‘ç°éœ€è¦é‡ç‚¹å…³æ³¨çš„é—®é¢˜ã€‚")
            md_content.append("")
            return
        
        md_content.append(f"ä»¥ä¸‹æ˜¯ **{len(selected_issues)}** ä¸ªéœ€è¦é‡ç‚¹å…³æ³¨çš„é—®é¢˜ï¼š")
        md_content.append("")
        
        for i, issue in enumerate(selected_issues, 1):
            severity = issue.get('severity', 'UNKNOWN')
            issue_type = issue.get('type', 'UNKNOWN')
            message = issue.get('message', 'æ— æè¿°')
            component = issue.get('component', '').split(':')[-1]  # åªå–æ–‡ä»¶åéƒ¨åˆ†
            line = issue.get('line', 'N/A')
            rule = issue.get('rule', 'unknown')
            
            # é—®é¢˜æ ‡é¢˜
            severity_emoji = {
                'BLOCKER': 'ğŸš«', 'CRITICAL': 'ğŸ”´', 'MAJOR': 'ğŸŸ ', 
                'MINOR': 'ğŸŸ¡', 'INFO': 'ğŸ”µ'
            }.get(severity, 'â“')
            
            type_emoji = {
                'BUG': 'ğŸ›', 'VULNERABILITY': 'ğŸ”“', 'CODE_SMELL': 'ğŸ’¨'
            }.get(issue_type, 'â“')
            
            md_content.append(f"### {i}. {severity_emoji} {type_emoji} {severity} - {issue_type}")
            md_content.append("")
            
            # è‹±æ–‡æè¿°å’Œä¸­æ–‡ç¿»è¯‘
            md_content.append(f"**é—®é¢˜æè¿°**: {message}")
            chinese_description = self._get_chinese_description(message, rule)
            if chinese_description and chinese_description != message:
                md_content.append(f"**ä¸­æ–‡è¯´æ˜**: {chinese_description}")
            md_content.append("")
            
            md_content.append(f"**ä½ç½®**: `{component}:{line}`")
            md_content.append("")
            
            # è§„åˆ™å’Œè§„åˆ™è§£é‡Š
            rule_explanation = self._get_rule_explanation(rule)
            md_content.append(f"**è§„åˆ™**: `{rule}`")
            if rule_explanation:
                md_content.append(f"**è§„åˆ™è¯´æ˜**: {rule_explanation}")
            md_content.append("")
            
            # æ·»åŠ ä¿®å¤å»ºè®®
            fix_suggestion = self._get_fix_suggestion(issue_type, severity, rule)
            if fix_suggestion:
                md_content.append(f"**ä¿®å¤å»ºè®®**: {fix_suggestion}")
                md_content.append("")
            
            md_content.append("---")
            md_content.append("")
        
        md_content.append("")
    
    def _get_fix_suggestion(self, issue_type: str, severity: str, rule: str) -> str:
        """è·å–é—®é¢˜ä¿®å¤å»ºè®®"""        
        # ç‰¹æ®Šè§„åˆ™çš„å…·ä½“ä¿®å¤å»ºè®®
        rule_suggestions = {
            'java:S1172': """**ä¿®å¤æ–¹æ³•**: ç§»é™¤æœªä½¿ç”¨çš„å‚æ•°
```java
// âŒ ä¿®å¤å‰
public void process(String data, int unusedParam) { }

// âœ… ä¿®å¤å  
public void process(String data) { }
```""",
            
            'java:S1481': """**ä¿®å¤æ–¹æ³•**: ç§»é™¤æœªä½¿ç”¨çš„å˜é‡
```java
// âŒ ä¿®å¤å‰
public void method() {
    String unused = "test";
    doSomething();
}

// âœ… ä¿®å¤å
public void method() {
    doSomething();
}
```""",
            
            'java:S1118': """**ä¿®å¤æ–¹æ³•**: æ·»åŠ ç§æœ‰æ„é€ å‡½æ•°
```java
// âŒ ä¿®å¤å‰
public class Utils {
    public static void helper() { }
}

// âœ… ä¿®å¤å
public class Utils {
    private Utils() { }
    public static void helper() { }
}
```""",
            
            'java:S2095': """**ä¿®å¤æ–¹æ³•**: ä½¿ç”¨try-with-resources
```java
// âŒ ä¿®å¤å‰
FileInputStream fis = new FileInputStream(file);
// ... ä½¿ç”¨fis
fis.close();

// âœ… ä¿®å¤å
try (FileInputStream fis = new FileInputStream(file)) {
    // ... ä½¿ç”¨fis
}
```""",
            
            'java:S1144': """**ä¿®å¤æ–¹æ³•**: ç§»é™¤æœªä½¿ç”¨çš„ç§æœ‰æ–¹æ³•
```java
// âŒ ä¿®å¤å‰
private void unusedMethod() { }

// âœ… ä¿®å¤å
// ç›´æ¥åˆ é™¤è¯¥æ–¹æ³•
```""",
            
            'squid:S00108': """**ä¿®å¤æ–¹æ³•**: ç§»é™¤ç©ºä»£ç å—æˆ–æ·»åŠ æ³¨é‡Š
```java
// âŒ ä¿®å¤å‰
if (condition) {
    // ç©ºä»£ç å—
}

// âœ… ä¿®å¤å
if (condition) {
    // TODO: å®ç°å…·ä½“é€»è¾‘
}
```""",
        }
        
        # ä¼˜å…ˆè¿”å›è§„åˆ™ç‰¹å®šå»ºè®®
        if rule in rule_suggestions:
            return rule_suggestions[rule]
        
        # é€šç”¨å»ºè®®
        general_suggestions = {
            'BUG': {
                'BLOCKER': 'ğŸš¨ **ç«‹å³ä¿®å¤**: ç³»ç»Ÿé˜»å¡æ€§é”™è¯¯ï¼Œå¿…é¡»åœ¨å‘å¸ƒå‰è§£å†³',
                'CRITICAL': 'ğŸ”´ **1-2å¤©å†…ä¿®å¤**: ä¸¥é‡é€»è¾‘é”™è¯¯ï¼Œå½±å“æ ¸å¿ƒåŠŸèƒ½',
                'MAJOR': 'ğŸŸ  **1å‘¨å†…ä¿®å¤**: é‡è¦åŠŸèƒ½é—®é¢˜ï¼Œéœ€è¦åŠæ—¶å¤„ç†'
            },
            'VULNERABILITY': {
                'BLOCKER': 'ğŸš¨ **ç«‹å³ä¿®å¤**: ä¸¥é‡å®‰å…¨æ¼æ´ï¼Œå­˜åœ¨è¢«æ”»å‡»é£é™©',
                'CRITICAL': 'ğŸ”´ **ç´§æ€¥ä¿®å¤**: é«˜å®‰å…¨é£é™©ï¼Œéœ€è¦ç«‹å³è¯„ä¼°å’Œä¿®å¤',
                'MAJOR': 'ğŸŸ  **åŠæ—¶ä¿®å¤**: æ½œåœ¨å®‰å…¨é£é™©ï¼Œåº”å°½å¿«å¤„ç†'
            },
            'CODE_SMELL': {
                'MAJOR': 'ğŸ’¨ **é‡æ„ä¼˜åŒ–**: ä»£ç ç»“æ„é—®é¢˜ï¼Œå½±å“ç»´æŠ¤æ€§',
                'MINOR': 'ğŸ”§ **é€‚æ—¶ä¼˜åŒ–**: ä»£ç è´¨é‡å¯ä»¥æ”¹å–„',
                'INFO': 'ğŸ’¡ **å‚è€ƒå»ºè®®**: æœ€ä½³å®è·µå»ºè®®ï¼Œå¯é€æ­¥æ”¹è¿›'
            }
        }
        
        # è¿”å›ç±»å‹å’Œä¸¥é‡ç¨‹åº¦ç›¸å…³å»ºè®®
        if issue_type in general_suggestions and severity in general_suggestions[issue_type]:
            return general_suggestions[issue_type][severity]
        
        # é»˜è®¤å»ºè®®
        return f"å»ºè®®æŸ¥çœ‹SonarQubeè§„åˆ™è¯¦æƒ…ï¼Œäº†è§£å…·ä½“ä¿®å¤æ–¹æ³•"
    
    def _get_chinese_description(self, english_message: str, rule: str = None) -> str:
        """è·å–é—®é¢˜çš„ä¸­æ–‡æè¿°"""
        # å¸¸è§é—®é¢˜çš„ä¸­æ–‡ç¿»è¯‘
        chinese_translations = {
            # Javaå¸¸è§é—®é¢˜
            "Remove this unused method parameter": "ç§»é™¤è¿™ä¸ªæœªä½¿ç”¨çš„æ–¹æ³•å‚æ•°",
            "Remove this unused local variable": "ç§»é™¤è¿™ä¸ªæœªä½¿ç”¨çš„å±€éƒ¨å˜é‡", 
            "Add a private constructor to hide the implicit public one": "æ·»åŠ ç§æœ‰æ„é€ å‡½æ•°æ¥éšè—éšå¼çš„å…¬å…±æ„é€ å‡½æ•°",
            "Use try-with-resources or close this": "ä½¿ç”¨try-with-resourcesæˆ–è€…å…³é—­è¿™ä¸ªèµ„æº",
            "Remove this unused private method": "ç§»é™¤è¿™ä¸ªæœªä½¿ç”¨çš„ç§æœ‰æ–¹æ³•",
            "Either remove or fill this block of code": "ç§»é™¤æˆ–å¡«å……è¿™ä¸ªä»£ç å—",
            "Make this field final": "å°†è¿™ä¸ªå­—æ®µè®¾ä¸ºfinal",
            "Replace this lambda with a method reference": "ç”¨æ–¹æ³•å¼•ç”¨æ›¿æ¢è¿™ä¸ªlambdaè¡¨è¾¾å¼",
            "Cognitive Complexity": "è®¤çŸ¥å¤æ‚åº¦è¿‡é«˜ï¼Œå»ºè®®ç®€åŒ–ä»£ç é€»è¾‘",
            "Cyclomatic Complexity": "åœˆå¤æ‚åº¦è¿‡é«˜ï¼Œå»ºè®®æ‹†åˆ†æ–¹æ³•",
            
            # é€šç”¨é—®é¢˜ç±»å‹
            "unused": "å­˜åœ¨æœªä½¿ç”¨çš„ä»£ç å…ƒç´ ",
            "complexity": "ä»£ç å¤æ‚åº¦è¿‡é«˜", 
            "duplicate": "å­˜åœ¨é‡å¤ä»£ç ",
            "security": "å­˜åœ¨å®‰å…¨é£é™©",
            "resource": "èµ„æºç®¡ç†é—®é¢˜",
            "null": "å¯èƒ½çš„ç©ºæŒ‡é’ˆé—®é¢˜",
        }
        
        # ç²¾ç¡®åŒ¹é…
        if english_message in chinese_translations:
            return chinese_translations[english_message]
        
        # æ¨¡ç³ŠåŒ¹é…
        message_lower = english_message.lower()
        for keyword, translation in chinese_translations.items():
            if keyword.lower() in message_lower:
                return translation
                
        return ""  # æ²¡æœ‰æ‰¾åˆ°ç¿»è¯‘
    
    def _get_rule_explanation(self, rule: str) -> str:
        """è·å–è§„åˆ™è§£é‡Š"""
        rule_explanations = {
            'java:S1172': 'æ£€æµ‹æ–¹æ³•ä¸­æœªä½¿ç”¨çš„å‚æ•°ï¼Œè¿™äº›å‚æ•°ä¼šå¢åŠ ä»£ç å¤æ‚åº¦',
            'java:S1481': 'æ£€æµ‹æœªä½¿ç”¨çš„å±€éƒ¨å˜é‡ï¼Œåº”è¯¥ç§»é™¤ä»¥ä¿æŒä»£ç æ¸…æ´',
            'java:S1118': 'å·¥å…·ç±»åº”è¯¥æœ‰ç§æœ‰æ„é€ å‡½æ•°ï¼Œé˜²æ­¢è¢«å®ä¾‹åŒ–',
            'java:S2095': 'æ£€æµ‹èµ„æºæ˜¯å¦æ­£ç¡®å…³é—­ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼',
            'java:S1144': 'æ£€æµ‹æœªä½¿ç”¨çš„ç§æœ‰æ–¹æ³•ï¼Œåº”è¯¥ç§»é™¤ä»¥å‡å°‘ä»£ç å†—ä½™',
            'java:S00108': 'æ£€æµ‹ç©ºçš„ä»£ç å—ï¼Œåº”è¯¥ç§»é™¤æˆ–æ·»åŠ è¯´æ˜æ³¨é‡Š',
            'java:S1213': 'å¸¸é‡å®šä¹‰ä½ç½®å»ºè®®ï¼Œæé«˜ä»£ç ç»„ç»‡æ€§',
            'java:S3776': 'æ–¹æ³•è®¤çŸ¥å¤æ‚åº¦è¿‡é«˜ï¼Œå»ºè®®æ‹†åˆ†æ–¹æ³•',
            'java:S1541': 'æ–¹æ³•åœˆå¤æ‚åº¦è¿‡é«˜ï¼Œå»ºè®®ç®€åŒ–é€»è¾‘',
            'java:S1192': 'æ£€æµ‹é‡å¤çš„å­—ç¬¦ä¸²å­—é¢é‡ï¼Œå»ºè®®å®šä¹‰ä¸ºå¸¸é‡',
        }
        
        return rule_explanations.get(rule, "")
    
    def _add_practical_recommendations(self, md_content: list, analysis_data: dict):
        """æ·»åŠ åŠ¡å®çš„ä¿®å¤å»ºè®®éƒ¨åˆ†"""
        md_content.append("## ğŸ¯ åŠ¡å®ä¿®å¤å»ºè®®")
        md_content.append("")
        
        issues = analysis_data['issues']['raw_data']
        if not issues:
            md_content.append("âœ… é¡¹ç›®ä»£ç è´¨é‡è‰¯å¥½ï¼Œæ— éœ€ç‰¹åˆ«å…³æ³¨çš„é—®é¢˜ã€‚")
            md_content.append("")
            return
        
        # åˆ†æé—®é¢˜åˆ†å¸ƒ
        file_problems = {}  # æ–‡ä»¶ -> é—®é¢˜åˆ—è¡¨
        severity_stats = {'BLOCKER': 0, 'CRITICAL': 0, 'MAJOR': 0, 'MINOR': 0, 'INFO': 0}
        
        for issue in issues:
            if isinstance(issue, dict):
                component = issue.get('component', '')
                severity = issue.get('severity', 'UNKNOWN')
                
                # æå–æ–‡ä»¶å
                if ':' in component:
                    filename = component.split(':')[-1]
                else:
                    filename = component
                
                if filename not in file_problems:
                    file_problems[filename] = []
                file_problems[filename].append(issue)
                
                if severity in severity_stats:
                    severity_stats[severity] += 1
        
        # 1. æœ€æ€¥éœ€ä¿®å¤çš„æ–‡ä»¶
        md_content.append("### ğŸš¨ æœ€æ€¥éœ€ä¿®å¤çš„æ–‡ä»¶ (Top 5)")
        md_content.append("")
        
        # æŒ‰é—®é¢˜æ•°é‡å’Œä¸¥é‡ç¨‹åº¦æ’åºæ–‡ä»¶
        file_scores = {}
        for filename, file_issues in file_problems.items():
            score = 0
            critical_count = 0
            major_count = 0
            
            for issue in file_issues:
                severity = issue.get('severity', '')
                if severity == 'BLOCKER':
                    score += 10
                    critical_count += 1
                elif severity == 'CRITICAL':
                    score += 8
                    critical_count += 1
                elif severity == 'MAJOR':
                    score += 5
                    major_count += 1
                elif severity == 'MINOR':
                    score += 2
                else:
                    score += 1
            
            file_scores[filename] = {
                'score': score,
                'total': len(file_issues),
                'critical': critical_count,
                'major': major_count
            }
        
        # æ’åºå¹¶æ˜¾ç¤ºå‰5ä¸ª
        top_files = sorted(file_scores.items(), key=lambda x: x[1]['score'], reverse=True)[:5]
        
        for i, (filename, stats) in enumerate(top_files, 1):
            critical_major = stats['critical'] + stats['major']
            md_content.append(f"**{i}. `{filename}`**")
            md_content.append(f"- ğŸ”¥ **{stats['total']}ä¸ªé—®é¢˜** ({stats['critical']}ä¸ªä¸¥é‡ + {stats['major']}ä¸ªé‡è¦)")
            md_content.append(f"- ğŸ’¡ **å»ºè®®**: {'ç«‹å³ä¿®å¤' if stats['critical'] > 0 else 'æœ¬å‘¨å†…å¤„ç†'}")
            md_content.append("")
        
        # 2. æŒ‰é—®é¢˜ç±»å‹çš„å…·ä½“å»ºè®®
        md_content.append("### ğŸ› ï¸ åˆ†ç±»ä¿®å¤ç­–ç•¥")
        md_content.append("")
        
        issue_stats = analysis_data['summary']['issue_stats']
        
        # BUGä¿®å¤å»ºè®®
        bug_count = issue_stats['by_type'].get('BUG', 0)
        if bug_count > 0:
            md_content.append(f"#### ğŸ› BUGä¿®å¤ ({bug_count}ä¸ª)")
            md_content.append("**ç«‹å³è¡ŒåŠ¨**:")
            md_content.append("- ğŸš¨ å…ˆä¿®å¤æ‰€æœ‰BLOCKERå’ŒCRITICALçº§åˆ«çš„BUG")
            md_content.append("- ğŸ“‹ ä¸ºæ¯ä¸ªBUGåˆ›å»ºæµ‹è¯•ç”¨ä¾‹ï¼Œç¡®ä¿ä¿®å¤åä¸å†å‡ºç°")
            md_content.append("- ğŸ” é‡ç‚¹æ£€æŸ¥ç©ºæŒ‡é’ˆå¼‚å¸¸ã€æ•°ç»„è¶Šç•Œã€èµ„æºæ³„éœ²ç­‰å¸¸è§é—®é¢˜")
            md_content.append("")
        
        # æ¼æ´ä¿®å¤å»ºè®®
        vuln_count = issue_stats['by_type'].get('VULNERABILITY', 0)
        if vuln_count > 0:
            md_content.append(f"#### ğŸ”“ å®‰å…¨æ¼æ´ä¿®å¤ ({vuln_count}ä¸ª)")
            md_content.append("**å®‰å…¨ä¼˜å…ˆ**:")
            md_content.append("- ğŸ›¡ï¸ ç«‹å³ä¿®å¤æ‰€æœ‰å®‰å…¨æ¼æ´ï¼Œè¿™æ˜¯æœ€é«˜ä¼˜å…ˆçº§")
            md_content.append("- ğŸ” é‡ç‚¹å…³æ³¨ï¼šSQLæ³¨å…¥ã€XSSæ”»å‡»ã€æ•æ„Ÿä¿¡æ¯æ³„éœ²")
            md_content.append("- ğŸ“ å»ºç«‹å®‰å…¨ä»£ç å®¡æŸ¥æ£€æŸ¥æ¸…å•")
            md_content.append("")
        
        # ä»£ç å¼‚å‘³ä¿®å¤å»ºè®®
        smell_count = issue_stats['by_type'].get('CODE_SMELL', 0)
        if smell_count > 0:
            md_content.append(f"#### ğŸ’¨ ä»£ç å¼‚å‘³æ•´æ²» ({smell_count}ä¸ª)")
            md_content.append("**åˆ†æ‰¹å¤„ç†**:")
            md_content.append("- ğŸ¯ æ¯å‘¨å¤„ç†20-30ä¸ªCODE_SMELLï¼ŒæŒç»­æ”¹è¿›")
            md_content.append("- ğŸ”„ é‡ç‚¹å…³æ³¨ï¼šé‡å¤ä»£ç ã€å¤æ‚åº¦è¿‡é«˜ã€å‘½åä¸è§„èŒƒ")
            md_content.append("- ğŸ“Š è®¾ç½®è´¨é‡é—¨ï¼šæ–°ä»£ç ä¸èƒ½å¼•å…¥æ–°çš„CODE_SMELL")
            md_content.append("")
        
        # 3. æœ¬å‘¨è¡ŒåŠ¨è®¡åˆ’
        md_content.append("### ğŸ“… æœ¬å‘¨è¡ŒåŠ¨è®¡åˆ’")
        md_content.append("")
        
        total_critical = severity_stats['BLOCKER'] + severity_stats['CRITICAL']
        if total_critical > 0:
            md_content.append(f"#### ç¬¬ä¸€ä¼˜å…ˆçº§ - ç´§æ€¥ä¿®å¤ ({total_critical}ä¸ª)")
            md_content.append(f"- ğŸ“ **ç›®æ ‡**: æœ¬å‘¨å†…æ¸…é›¶æ‰€æœ‰BLOCKERå’ŒCRITICALé—®é¢˜")
            if total_critical <= 10:
                md_content.append(f"- â° **æ—¶é—´å®‰æ’**: æ¯å¤©å¤„ç†2-3ä¸ªï¼Œé¢„è®¡3-4å¤©å®Œæˆ")
            else:
                md_content.append(f"- â° **æ—¶é—´å®‰æ’**: æ¯å¤©å¤„ç†5-8ä¸ªï¼Œé¢„è®¡æœ¬å‘¨å®Œæˆå¤§éƒ¨åˆ†")
            md_content.append(f"- ğŸ‘¥ **å»ºè®®**: åˆ†é…ç»™æœ€æœ‰ç»éªŒçš„å¼€å‘äººå‘˜å¤„ç†")
            md_content.append("")
        
        major_count = severity_stats['MAJOR']
        if major_count > 0:
            md_content.append(f"#### ç¬¬äºŒä¼˜å…ˆçº§ - é‡è¦ä¿®å¤ ({major_count}ä¸ª)")
            md_content.append(f"- ğŸ“ **ç›®æ ‡**: 2å‘¨å†…å¤„ç†å®Œæ‰€æœ‰MAJORé—®é¢˜")
            md_content.append(f"- â° **æ—¶é—´å®‰æ’**: æ¯å¤©å¤„ç†3-5ä¸ª")
            md_content.append(f"- ğŸ¯ **é‡ç‚¹**: å½±å“åŠŸèƒ½å’Œæ€§èƒ½çš„é—®é¢˜")
            md_content.append("")
        
        # 4. è´¨é‡æ”¹è¿›å»ºè®®
        md_content.append("### ğŸš€ è´¨é‡æ”¹è¿›æªæ–½")
        md_content.append("")
        
        measures = analysis_data.get('measures', {})
        coverage = measures.get('coverage', 0)
        
        md_content.append("#### ç«‹å³å®æ–½çš„æ”¹è¿›æªæ–½:")
        md_content.append("")
        
        if coverage < 50:
            md_content.append("1. **ğŸ“Š æµ‹è¯•è¦†ç›–ç‡æå‡**")
            md_content.append(f"   - å½“å‰è¦†ç›–ç‡: {coverage}%ï¼Œç›®æ ‡: 70%+")
            md_content.append("   - ä¼˜å…ˆä¸ºæ ¸å¿ƒä¸šåŠ¡é€»è¾‘ç¼–å†™å•å…ƒæµ‹è¯•")
            md_content.append("   - ä½¿ç”¨JUnit + Mockitoæ­å»ºæµ‹è¯•æ¡†æ¶")
            md_content.append("")
        
        md_content.append("2. **ğŸ”§ ä»£ç å®¡æŸ¥æµç¨‹**")
        md_content.append("   - æ¯ä¸ªPRå¿…é¡»ç»è¿‡SonarQubeæ‰«æ")
        md_content.append("   - ä¸å…è®¸æ–°å¢CRITICALä»¥ä¸Šé—®é¢˜")
        md_content.append("   - å»ºç«‹ä»£ç è´¨é‡æ£€æŸ¥æ¸…å•")
        md_content.append("")
        
        md_content.append("3. **ğŸ“ˆ æŒç»­æ”¹è¿›**")
        md_content.append("   - è®¾å®šæ¯å‘¨ä¿®å¤é—®é¢˜æ•°é‡ç›®æ ‡")
        md_content.append("   - å®šæœŸï¼ˆæ¯æœˆï¼‰è¿›è¡Œä»£ç è´¨é‡è¯„å®¡")
        md_content.append("   - å»ºç«‹æŠ€æœ¯å€ºåŠ¡ç®¡ç†æœºåˆ¶")
        md_content.append("")
        
        # 5. æŠ•å…¥äº§å‡ºä¼°ç®—
        total_issues = len(issues)
        estimated_hours = self._estimate_fix_time(severity_stats, total_issues)
        
        md_content.append("### ğŸ’° æŠ•å…¥äº§å‡ºä¼°ç®—")
        md_content.append("")
        md_content.append(f"**é¢„ä¼°ä¿®å¤å·¥ä½œé‡**: `{estimated_hours}`å°æ—¶")
        md_content.append(f"**å»ºè®®å›¢é˜Ÿé…ç½®**: {self._recommend_team_size(total_issues)}äºº")
        md_content.append(f"**é¢„æœŸå®Œæˆæ—¶é—´**: {self._estimate_completion_time(total_issues)}å‘¨")
        md_content.append("")
        md_content.append("**æ”¶ç›Šé¢„æœŸ**:")
        md_content.append("- ğŸš€ ç³»ç»Ÿç¨³å®šæ€§æå‡60%+")
        md_content.append("- ğŸ›¡ï¸ å®‰å…¨é£é™©é™ä½80%+") 
        md_content.append("- ğŸ”§ åæœŸç»´æŠ¤æˆæœ¬é™ä½40%+")
        md_content.append("- ğŸ‘¨â€ğŸ’» æ–°äººä¸Šæ‰‹æ—¶é—´ç¼©çŸ­50%+")
        md_content.append("")
    
    def _estimate_fix_time(self, severity_stats: dict, total_issues: int) -> str:
        """ä¼°ç®—ä¿®å¤æ—¶é—´"""
        hours = 0
        hours += severity_stats.get('BLOCKER', 0) * 4  # æ¯ä¸ªBLOCKER 4å°æ—¶
        hours += severity_stats.get('CRITICAL', 0) * 3  # æ¯ä¸ªCRITICAL 3å°æ—¶
        hours += severity_stats.get('MAJOR', 0) * 2  # æ¯ä¸ªMAJOR 2å°æ—¶
        hours += severity_stats.get('MINOR', 0) * 1  # æ¯ä¸ªMINOR 1å°æ—¶
        hours += severity_stats.get('INFO', 0) * 0.5  # æ¯ä¸ªINFO 0.5å°æ—¶
        
        return f"{int(hours)}-{int(hours * 1.5)}"
    
    def _recommend_team_size(self, total_issues: int) -> str:
        """æ¨èå›¢é˜Ÿè§„æ¨¡"""
        if total_issues < 50:
            return "1-2"
        elif total_issues < 200:
            return "2-3"
        elif total_issues < 500:
            return "3-4"
        else:
            return "4-5"
    
    def _estimate_completion_time(self, total_issues: int) -> str:
        """ä¼°ç®—å®Œæˆæ—¶é—´"""
        if total_issues < 50:
            return "2-3"
        elif total_issues < 200:
            return "4-6"
        elif total_issues < 500:
            return "6-10"
        else:
            return "10-16"
    
    def _get_rating_emoji(self, rating: str) -> str:
        """è·å–è¯„çº§å¯¹åº”çš„emoji"""
        rating_emojis = {
            'A': 'ğŸŸ¢',
            'B': 'ğŸŸ¡', 
            'C': 'ğŸŸ ',
            'D': 'ğŸ”´',
            'E': 'ğŸ”´'
        }
        return rating_emojis.get(str(rating).upper(), 'â“')
    
    def convert_markdown_to_html(self, markdown_content: str) -> str:
        """å°†Markdownè½¬æ¢ä¸ºHTML"""
        try:
            # é…ç½®markdownæ‰©å±•
            extensions = [
                'markdown.extensions.tables',
                'markdown.extensions.codehilite',
                'markdown.extensions.fenced_code',
                'markdown.extensions.toc'
            ]
            
            # è½¬æ¢ä¸ºHTML
            html = markdown.markdown(markdown_content, extensions=extensions)
            
            # æ·»åŠ CSSæ ·å¼
            styled_html = f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>SonarQubeé¡¹ç›®ç¼ºé™·åˆ†ææŠ¥å‘Š</title>
    <style>
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
            line-height: 1.6;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            color: #333;
        }}
        
        h1, h2, h3 {{
            color: #2c3e50;
            border-bottom: 1px solid #ecf0f1;
            padding-bottom: 10px;
        }}
        
        h1 {{ color: #e74c3c; }}
        h2 {{ color: #3498db; }}
        h3 {{ color: #f39c12; }}
        
        code {{
            background-color: #f8f9fa;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: 'Monaco', 'Menlo', monospace;
        }}
        
        pre {{
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
        }}
        
        blockquote {{
            border-left: 4px solid #3498db;
            padding-left: 20px;
            margin: 20px 0;
            background-color: #f8f9fa;
            padding: 15px 20px;
            border-radius: 5px;
        }}
        
        table {{
            border-collapse: collapse;
            width: 100%;
            margin: 20px 0;
        }}
        
        th, td {{
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }}
        
        th {{
            background-color: #f2f2f2;
            font-weight: bold;
        }}
        
        .risk-critical {{ background-color: #ffeaa7; }}
        .risk-high {{ background-color: #fab1a0; }}
        .risk-medium {{ background-color: #e17055; }}
        .risk-low {{ background-color: #00b894; }}
        .risk-minimal {{ background-color: #ddd; }}
        
        .timestamp {{
            color: #7f8c8d;
            font-style: italic;
            text-align: right;
            margin-top: 30px;
        }}
    </style>
</head>
<body>
{html}
<div class="timestamp">
    æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {format_timestamp()}
</div>
</body>
</html>
"""
            return styled_html
            
        except Exception as e:
            self.logger.error(f"Markdownè½¬HTMLå¤±è´¥: {e}")
            return f"<html><body><h1>è½¬æ¢å¤±è´¥</h1><p>{str(e)}</p></body></html>"
    
    def send_report_email(self, html_content: str, recipients: List[str],
                         subject: str = None, project_name: str = None, 
                         markdown_content: str = None) -> Dict[str, Any]:
        """å‘é€HTMLæ ¼å¼çš„é‚®ä»¶æŠ¥å‘Š"""
        try:
            if not subject:
                date_str = datetime.now().strftime('%Y-%m-%d')
                subject = f"SonarQubeé¡¹ç›®ç¼ºé™·åˆ†ææŠ¥å‘Š - {project_name or self.project_key} ({date_str})"
            
            self.logger.info(f"ğŸ“§ é‚®ä»¶ä¸»é¢˜: {subject}")
            
            # å¦‚æœæœ‰markdownå†…å®¹ï¼Œåˆ™å‘é€HTMLé‚®ä»¶å¹¶é™„ä¸Šmarkdownæ–‡ä»¶
            if markdown_content:
                # ç”Ÿæˆé™„ä»¶æ–‡ä»¶å
                date_str = datetime.now().strftime('%Y%m%d_%H%M%S')
                project_name_safe = (project_name or self.project_key).replace('/', '_').replace(' ', '_')
                attachment_filename = f"SonarQubeç¼ºé™·åˆ†ææŠ¥å‘Š_{project_name_safe}_{date_str}.md"
                
                self.logger.info(f"ğŸ“ é™„ä»¶æ–‡ä»¶å: {attachment_filename}")
                self.logger.info(f"ğŸ“ é™„ä»¶å¤§å°: {len(markdown_content)} å­—ç¬¦")
                self.logger.info("æ­£åœ¨å‘é€HTMLé‚®ä»¶ï¼ˆåŒ…å«Markdowné™„ä»¶ï¼‰...")
                
                return self.notification_sender.send_html_email_with_attachment(
                    subject, html_content, recipients, 
                    markdown_content, attachment_filename
                )
            else:
                # ä»…å‘é€HTMLé‚®ä»¶
                self.logger.info("æ­£åœ¨å‘é€HTMLé‚®ä»¶ï¼ˆæ— é™„ä»¶ï¼‰...")
                return self.notification_sender.send_html_email(subject, html_content, recipients)
            
        except Exception as e:
            self.logger.error(f"å‘é€é‚®ä»¶å¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="SonarQubeé¡¹ç›®ç¼ºé™·åˆ†æå™¨")
    parser.add_argument('--project-key', required=True, help='SonarQubeé¡¹ç›®æ ‡è¯†ç¬¦')
    parser.add_argument('--severities', nargs='+', 
                       choices=['INFO', 'MINOR', 'MAJOR', 'CRITICAL', 'BLOCKER'],
                       default=['CRITICAL', 'BLOCKER', 'MAJOR'],
                       help='ä¸¥é‡ç¨‹åº¦è¿‡æ»¤')
    parser.add_argument('--issue-types', nargs='+',
                       choices=['CODE_SMELL', 'BUG', 'VULNERABILITY'],
                       default=['BUG', 'VULNERABILITY', 'CODE_SMELL'],
                       help='é—®é¢˜ç±»å‹è¿‡æ»¤')
    parser.add_argument('--use-ai', action='store_true', help='å¯ç”¨AIåˆ†æ')
    parser.add_argument('--ai-model', help='æŒ‡å®šAIåˆ†æä½¿ç”¨çš„æ¨¡å‹åç§°')
    parser.add_argument('--output-format', choices=['json', 'markdown', 'html'], 
                       default='html', help='è¾“å‡ºæ ¼å¼')
    parser.add_argument('--output-file', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--send-email', action='store_true', help='å‘é€é‚®ä»¶æŠ¥å‘Š')
    parser.add_argument('--email-recipients', nargs='+', help='é‚®ä»¶æ”¶ä»¶äººåˆ—è¡¨')
    parser.add_argument('--email-subject', help='é‚®ä»¶ä¸»é¢˜')
    
    # SonarQubeé…ç½®é€‰é¡¹
    parser.add_argument('--sonarqube-url', help='SonarQubeå®ä¾‹URL')
    parser.add_argument('--sonarqube-token', help='SonarQubeè®¿é—®ä»¤ç‰Œ')
    parser.add_argument('--sonarqube-timeout', type=int, help='SonarQube APIè¶…æ—¶æ—¶é—´')
    parser.add_argument('--sonarqube-verify-ssl', type=bool, help='æ˜¯å¦éªŒè¯SSLè¯ä¹¦')
    
    parser.add_argument('--log-level', default='INFO', help='æ—¥å¿—çº§åˆ«')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logging(args.log_level)
    
    try:
        # åˆ›å»ºSonarQubeé…ç½®
        sonarqube_config = None
        if any([args.sonarqube_url, args.sonarqube_token, args.sonarqube_timeout, 
                args.sonarqube_verify_ssl is not None]):
            from shared.sonarqube_client import get_default_sonarqube_config
            
            # è·å–é»˜è®¤é…ç½®
            default_config = get_default_sonarqube_config()
            
            # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é»˜è®¤é…ç½®
            sonarqube_config = SonarQubeConfig(
                url=args.sonarqube_url or default_config.url,
                token=args.sonarqube_token or default_config.token,
                timeout=args.sonarqube_timeout or default_config.timeout,
                verify_ssl=args.sonarqube_verify_ssl if args.sonarqube_verify_ssl is not None else default_config.verify_ssl
            )
        
        # åˆ›å»ºSonarQubeå®¢æˆ·ç«¯
        sonarqube_client = SonarQubeClient(sonarqube_config) if sonarqube_config else None
        
        # åˆ›å»ºåˆ†æå™¨
        analyzer = SonarQubeDefectAnalyzer(
            args.project_key, 
            sonarqube_client=sonarqube_client,
            ai_model=args.ai_model
        )
        
        # æ‰§è¡Œåˆ†æ
        logger.info("å¼€å§‹åˆ†æSonarQubeé¡¹ç›®ç¼ºé™·...")
        analysis_data = analyzer.analyze_project_defects(
            severities=args.severities,
            issue_types=args.issue_types,
            use_ai=args.use_ai
        )
        
        # è¾“å‡ºç»“æœ
        logger.info(f"å¼€å§‹ç”Ÿæˆ {args.output_format} æ ¼å¼çš„æŠ¥å‘Š...")
        markdown_content = None
        if args.output_format == 'json':
            output_content = json.dumps(analysis_data, indent=2, ensure_ascii=False, default=str)
        elif args.output_format == 'markdown':
            logger.info("æ­£åœ¨ç”ŸæˆMarkdownæŠ¥å‘Š...")
            markdown_content = analyzer.generate_markdown_report(analysis_data)
            output_content = markdown_content
        elif args.output_format == 'html':
            logger.info("æ­£åœ¨ç”ŸæˆMarkdownæŠ¥å‘Š...")
            markdown_content = analyzer.generate_markdown_report(analysis_data)
            logger.info("æ­£åœ¨è½¬æ¢ä¸ºHTMLæ ¼å¼...")
            output_content = analyzer.convert_markdown_to_html(markdown_content)
        logger.info("æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        if args.output_file:
            with open(args.output_file, 'w', encoding='utf-8') as f:
                f.write(output_content)
            logger.info(f"åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output_file}")
        
        # å‘é€é‚®ä»¶
        if args.send_email and args.email_recipients:
            logger.info("å¼€å§‹å‘é€é‚®ä»¶æŠ¥å‘Š...")
            logger.info(f"æ”¶ä»¶äºº: {', '.join(args.email_recipients)}")
            
            if args.output_format == 'html':
                result = analyzer.send_report_email(
                    html_content=output_content,
                    recipients=args.email_recipients,
                    subject=args.email_subject,
                    project_name=analysis_data['project_info']['name'],
                    markdown_content=markdown_content
                )
                
                if result['success']:
                    logger.info("âœ… HTMLé‚®ä»¶å‘é€æˆåŠŸ")
                    logger.info(f"å·²å‘é€ç»™ {len(args.email_recipients)} ä¸ªæ”¶ä»¶äºº")
                else:
                    logger.error(f"âŒ é‚®ä»¶å‘é€å¤±è´¥: {result.get('error')}")
            else:
                logger.warning("âš ï¸ åªæœ‰HTMLæ ¼å¼æ‰æ”¯æŒå‘é€é‚®ä»¶")
        
        # è¾“å‡ºæ‘˜è¦
        summary = analysis_data['summary']
        print(f"âœ… åˆ†æå®Œæˆ")
        print(f"   é¡¹ç›®: {analysis_data['project_info']['name']}")
        print(f"   é¡¹ç›®æ ‡è¯†: {args.project_key}")
        print(f"   æ€»é—®é¢˜æ•°: {summary['issue_stats']['total']}")
        print(f"   å®‰å…¨çƒ­ç‚¹: {summary['hotspot_stats']['total']}")
        print(f"   é£é™©ç­‰çº§: {summary['risk_level']}")
        print(f"   è´¨é‡é—¨çŠ¶æ€: {summary['quality_gate_status']}")
        
        if not args.output_file and not args.send_email:
            print("\n" + output_content)
        
    except Exception as e:
        import traceback
        logger.error(f"åˆ†æå¤±è´¥: {e}")
        logger.error(f"å®Œæ•´å †æ ˆä¿¡æ¯:\n{traceback.format_exc()}")
        sys.exit(1)

if __name__ == "__main__":
    main()